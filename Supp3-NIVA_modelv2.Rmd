---
title: "Supplementary 3 - SELM test on data from the 1000 lakes survey 2019"
author: "Camille Crapart"
date: "4 4 2022"
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide 
bibliography: C:\\Users\\raine\\Documents\\UiO\\Bibtex\\Finstad.bib
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, collapse = T, message = F, warning = F, error = F, fig.align = "center")
```

```{r libraries}
library(readxl)
library(ggplot2)
library(grid)
library(gridExtra)
library(png)
library(sf)
library(spatialreg)
library(RColorBrewer)
memory.limit(size = 160000)
```

# 1000-lakes survey dataset

The data from the 1000-lakes survey in 2019 was provided by NIVA and is available on GitHub.   

## NIVA data

All the catchment data (from ???) and the chemistry data (from the survey conducted by NIVA in 2019, @NIVA2020) were included in the dataset provided by NIVA. The catchment polygons as well as the sampling points were also calculated and provided by NIVA. The only parameter missing was the NDVI, which was subsequently extracted based on the catchment polygons.

```{r load-geometry, eval = T}
lake.poly <- st_read("C:/Users/raine/Documents/UiO/Paper_3/catchments_poly/lakes1000cat.shp")
lake.point <- st_read("C:/Users/raine/Documents/UiO/Paper_3/catchments_poly/lakes1000stations.shp")
```

```{r load-niva-dataset}
niva <- read_xlsx("NIVA_test/niva_selection.xlsx")
```

```{r compare-datasets, eval = F}
nor <- st_read("Country_shapefile/norway.shp")

g <- ggplot()+
  geom_sf(data = nor, fill = "white")+
  geom_sf(data=lake.point,size = 1, aes(col = "Sampling point"))+
  geom_point(data = niva, aes(x=longitude,y=latitude, col = "TOC datapoints"),size = 0.5)+
  geom_sf(data=lake.poly, aes(col = "Catchment polygons"),fill = "gray", alpha = 0.5)+
  scale_color_manual(values = c("gray","black","red"))+
  theme_minimal()+theme(legend.title = element_blank())
ggsave(plot = g, filename = "NIVA_test/check_point.png",dpi = "retina", width = 15, height = 15, units = "cm", device = "png")

```

```{r comparare-datasets-plot}
knitr::include_graphics("NIVA_test/check_point.png")
```

```{r match-fennoscandia-lakes}
fennoscandia.33 <- readRDS("fennoscandia.33.rds")

niva.sf <- st_as_sf(niva,coords=c("longitude","latitude"))
st_crs(niva.sf) <- "+proj=longlat +datum=WGS84 +no_defs"
niva.sf <- niva.sf %>% st_transform(crs(fennoscandia.33))

niva.match <- st_join(niva.sf, dplyr::select(fennoscandia.33,c("ebint","nation","TOC","geom")), join =st_within)
niva.poly <- merge( dplyr::select(fennoscandia.33,c("ebint","geom")),st_drop_geometry(niva.match), by.x = "ebint", by.y = "ebint", all.x = F)

saveRDS(niva.poly,"NIVA_test/niva.poly.rds")

ggplot()+geom_sf(data = niva.poly, aes(fill = "TOC"))
```
 
## NDVI 

The NDVI was extracted for the year 2015 from the GIMMS dataset, as data from this database was not available for later dates. Other databases like Copernicus could have provided this data, but GIMMS was used for the original model and we assumed that the changes in mean NDVI are minimal in 3 years (as NDVI is taken for y-1). For details about the extraction of NDVI on the catchment, see Supplementary 1.

```{r download-NDVI-raster-2015, eval = F}
# http://poles.tpdc.ac.cn/en/data/9775f2b4-7370-4e5e-a537-3482c9a83d88/
library(gimms)
ndvi.2015 <- downloadGimms(x= 2015,y=2015,dsn = "NDVI")
 
ndvi.max.2015 <- monthlyComposite(ndvi.2015,monthlyIndices(ndvi.2015))
saveRDS(ndvi.max.2015,"NIVA_test/ndvi.max.2015.rds")
```

```{r NDVI, eval = F}
ndvi.max.2015 <- readRDS("NIVA_test/ndvi.max.2015.rds")

# Makes the raster smaller, ensuring faster processing of the data
summer.scandinavia.2015 <- raster::crop(ndvi.max.2015,c(0,35,55,73))


summer.scan <- reclassify(summer.scandinavia.2015, cbind(-Inf, 0, NA), right=FALSE)

summer.mean.2015 <- raster::stack(summer.scan[[6]],summer.scan[[7]],summer.scan[[8]]) %>% mean()

summer.ndvi.2015 <- raster::extract(summer.mean.2015,niva.poly, fun = mean, df = T, sp = T, na.rm = T)
names(summer.ndvi.2015) <- c("station_id","ndvi")
summer.ndvi.2015$NDVI <- floor(summer.ndvi.2015$ndvi/10)/1000

saveRDS(summer.ndvi.2015, "NIVA_test/100lakes.summer.ndvi.2015.rds")
write.csv(summer.ndvi.2015,"NIVA_test/100lakes.summer.ndvi.2015.csv")
```

### Runoff

```{r runoff-niva, eval = F}

runoff.raster <- "CORDEX/mrros_Lmon_CNRM-CM6-1-HR_historical_r1i1p1f2_gr_185001-201412.nc"
runoff.nc <- nc_open(runoff.raster)

runoff.stack <- raster::stack(runoff.raster, bands = c(1441:1812))
runoff.mean <- runoff.stack %>% mean() 

wr.sf <- readRDS("WR/wr.sf.rds")
runoff.wr95 <- raster::extract(runoff.mean, wr.sf, fun = mean, df = T, sp = T, na.rm = T)
names(runoff.wr95) <- c("gid","area","runoff")
saveRDS(runoff.wr95,"WR/runoff.wr95.rds")

ggplot(st_as_sf(runoff.wr95))+geom_sf(aes(fill=runoff,col=runoff))

```

### Corine Land Cover

The Land Cover data was downloaded from https://land.copernicus.eu/pan-european/corine-land-cover/clc2018. We used the 2018 version, the lst available. 

The land cover data was downloaded as a raster (.tiff file)

<!-- , which included the legend recording the code for each land use. The raster and legend were assembled in QGIS before being imported as a shapefile in R. The codes (corresponding to the line in the extracted dataframe) of the categories of interest were: -->

Arable land:
* 12: non-irrigated arable land
* 16: fruit trees and berries plantations
* 18: pastures
* 19: annual crops associated with permanent crops
* 20: Complex cultivation patterns

Bogs:
* 36: peat bogs
* 35: inland marshes, excluded because all zeros in the studied area.

Forest:
* 23: Broad-leaved forest
* 24: Coniferous forest
* 25: Mixed forest

Bare:
31: Bare rocks
32: Sparsely vegetated areas
33: Burnt areas

```{r extract-land-cover, eval = F}
niva.poly <- readRDS("NIVA_test/niva.poly.rds")
corine.2018 <- raster::raster("NIVA_test/CLC/U2018_CLC2018_V2020_20u1.tif")
plot(corine.2018)

clc.niva <- raster::extract(corine.2018,niva.poly)
saveRDS(clc.niva,"NIVA_test/CLC/clc.niva.rds")
```
```{r corine-tab-prop, eval = F}
clc.niva <- readRDS("NIVA_test/CLC/clc.niva.rds")
clc.tab <- sapply(clc.niva, function(x) tabulate(x,45))
clc.tab.area <- clc.tab*prod(res(corine.2018))
catchment.area <- colSums(clc.tab.area)
clc.tab.prop <- sweep(clc.tab.area,2,catchment.area, FUN = "/")
names(clc.tab.prop) <- catchment.poly.corine$ebint
saveRDS(clc.tab.prop,"NIVA_test/CLC/clc.tab.prop.niva.rds")
```

```{r corine-select-categories, eval = F}
clc.tab.prop <- readRDS("NIVA_test/CLC/clc.tab.prop.niva.rds") %>% as.data.frame()

bogs <- clc.tab.prop[36,] %>% t() %>% as.data.frame() %>% setNames("bogs") %>% tibble::rownames_to_column(var = "ebint")
saveRDS(bogs,"NIVA_test/CLC/bogs.niva.rds")
arable <- colSums(clc.tab.prop[c(12,16,18,19,20),]) %>% as.data.frame() %>% setNames("arable") %>% tibble::rownames_to_column(var = "ebint")
saveRDS(arable,"NIVA_test/CLC/arable.niva.rds")
forest <- colSums(clc.tab.prop[c(23,24,25),]) %>% as.data.frame() %>% setNames("forest") %>% tibble::rownames_to_column(var = "ebint")
saveRDS(forest,"NIVA_test/CLC/forest.niva.rds")
bare <- colSums(clc.tab.prop[c(31,32,33),]) %>% as.data.frame() %>% setNames("bare") %>% tibble::rownames_to_column(var = "ebint")
saveRDS(bare,"NIVA_test/CLC/bare.niva.rds")

```

### TNdep

The nitrogen and sulfur deposition data were extracted from the EMEP database (https://emep.int/mscw/mscw_moddata.html#Comp). The data from 2019 was used.

N-deposition (NOx and NH3) is the sum of: 
* Dry deposition of oxidized nitrogen per m2 grid DDEP_OXN_m2Grid, in mg/m2
* Wet deposition of oxidized nitrogen WDEP_OXN, in mg/m2 
* Dry deposition of oxidized nitrogen per m2 grid DDEP_RDN_m2Grid, in mg/m2
* Wet deposition of reduced nitrogen WDEP_RDN, in mg/m2

```{r extract Ndep, eval = F}
library(ncdf4)
EMEP_file <- "NIVA_test/Ndep/EMEP01_rv4.42_year.2019met_2019emis.nc"

niva.poly <- readRDS("catchment.poly.Rdata")

woxn <- raster(EMEP_file, varname = "WDEP_OXN") 
doxn <- raster(EMEP_file, varname = "DDEP_OXN_m2Grid")
wrdn <- raster(EMEP_file, varname = "WDEP_RDN")
drdn <- raster(EMEP_file, varname = "DDEP_RDN_m2Grid")

woxn_df <- extract(woxn,catchment.poly, sp = T, df = T, na.rm = T, fun = mean) 
names(woxn_df) <- c("ebint","woxn")
doxn_df <- extract(doxn,catchment.poly, sp = T, df = T, na.rm = T, fun = mean)
names(doxn_df) <- c("ebint","doxn")
wrdn_df <- extract(wrdn,catchment.poly, sp = T, df = T, na.rm = T, fun = mean)
names(wrdn_df) <- c("ebint","wrdn")
drdn_df <- extract(drdn,catchment.poly, sp = T, df = T, na.rm = T, fun = mean)
names(drdn_df) <- c("ebint","drdn")

ndep.df <- merge(woxn_df,doxn_df, by = "ebint") %>% merge(wrdn_df, by = "ebint") %>% merge(drdn_df, by = "ebint")
ndep.df$tndep <- rowSums(ndep.df@data[,c(2:5)])

saveRDS(ndep.df,"NIVA_test/Ndep/ndep.df.niva.rds")
```



## Gather dataset

The dataset from NIVA and the NDVI values were merged and the variables were given names matching the Fennoscandian dataset. The projection of the polygons was converted to the projection used in the present project (EU33).

```{r merge-data}
ndep.df.niva <- readRDS("NIVA_test/Ndep/ndep.df.niva.")
bogs.niva <- readRDS("NIVA_test/CLC/bogs.niva.rds")
arable.niva <- readRDS("NIVA_test/CLC/arable.niva.rds")
ndvi.niva <- readRDS("NIVA_test/100lakes.summer.ndvi.2015.rds")
niva.poly <- readRDS("NIVA_test/niva.poly.rds")

``` 

```{r niva-merged, eval = F}

summer.ndvi.2015 <- readRDS("NIVA_test/100lakes.summer.ndvi.2015.rds")
niva.ndvi <- sp::merge(summer.ndvi.2015, select(st_drop_geometry(lake.point), c("statn_d", "sttn_cd", "longitd", "latitud")), by.x = "station_id", by.y = "statn_d", all = T)

niva_data <- niva.ndvi %>% merge(select(niva, c("station_id","station_code", "agriculture","forest","peat","nilu_ndep_2012_2016","nilu_sdep_2012_2016", "rr_2m_19","era_prec_2019","era_temp_2019", "toc_2019")), by.y = "station_code", by.x = "sttn_cd") %>% st_as_sf()
niva_data$Runoff <- niva_data$rr_2m_19 %>% as.numeric()
niva_data$logRunoff <- log(niva_data$Runoff)
niva_data$Bog <- niva_data$peat/100
niva_data$Forest <- niva_data$forest/100
niva_data$Arable <- niva_data$agriculture/100
niva_data$TNdep <- niva_data$nilu_ndep_2012_2016 * 10
niva_data$TSdep <- niva_data$nilu_sdep_2012_2016 * 100
niva_data$Precip <- niva_data$era_prec_2019
niva_data$logPrecip <- niva_data$Precip %>% log()
niva_data$Temp <- niva_data$era_temp_2019

saveRDS(niva_data,"NIVA_test/niva_data.rds")
niva_data <- readRDS("NIVA_test/niva_data.rds")

niva_final <- niva_data[-which(is.na(niva_data$logRunoff) == T),]
niva_final <- niva_final[-which(is.na(niva_final$NDVI) == T), ]
#niva_final <- niva_final[-which(is.na(niva_final$Forest) == T), ]
#niva_final <- niva_final[-which(is.na(niva_final$Arable) == T), ]
niva_final <- niva_final[-which(is.na(niva_final$TNdep) == T), ]
# niva_final <- niva_final[-which(is.na(niva_final$TSdep) == T), ]

wr.sf.95 <- readRDS("WR/wr.sf.95.rds")
niva_final <- st_as_sf(niva_final) %>% st_transform(crs(wr.sf.95))
 
saveRDS(niva_final, "NIVA_test/niva_final.rds")
```
```{r plot-toc-niva}
niva_final <- readRDS("NIVA_test/niva_final.rds")
nor <- st_read("Country_shapefile/norway.shp") 

which(is.na(niva_final$toc_2019 == T))


ggplot()+ geom_sf(data = nor, fill = "white")+
  geom_sf(data = st_as_sf(niva_final), aes(fill = toc_2019, col = toc_2019))+
  scale_color_distiller(palette = 8, aesthetics = c("fill","col"), direction = 1)+
  labs(x ="", y = "")+
  theme_minimal()
```

# TOC prediction for NIVA dataset 

In order to predict the TOC in 2019 using the SELM, a neighbour matrix with the NIVA-lakes is first computed. 

```{r niva-kmat, eval = F}
niva_final <- readRDS("NIVA_test/niva_final.rds")
niva.kmat <- st_centroid(niva_final, of_largest_polygon = T) %>% knearneigh(k = 100) %>% knn2nb() %>% nb2listw()
saveRDS(niva.kmat,"NIVA_test/niva.kmat.rds")
```

The SELM is then applied to the 2019-dataset.

```{r predict-toc, eval = F}
sem.model <- readRDS("sem.fennoscandia.5.rds")
niva_final <- readRDS("NIVA_test/niva_final.rds")
niva.kmat <- readRDS("NIVA_test/niva.kmat.rds")

fm <- logTOC~NDVI+logRunoff+Bog+Arable+TNdep

niva_fit <- predict(sem.model, newdata = niva_final, niva.kmat)

niva_predict <- cbind(niva_final, niva_fit)
niva_predict$diffTOC <- niva_predict$toc_2019 - exp(niva_predict$fit)

niva_predict$diffLogTOC <- log(niva_predict$toc_2019) - niva_predict$fit

saveRDS(niva_predict,"NIVA_test/niva_predict.rds")

qplot(niva_final$logTOC, )
```

```{r plot-model-results}
niva_predict <- readRDS("NIVA_test/niva_predict.rds")

ggplot(niva_predict) + geom_point(aes(x = log(toc_2019), y = fit))+
  labs(x = "log(TOC 2019)", y = "Predicted log(TOC)",subtitle = "a)")+
  annotate(geom = "label", label = paste("r = ", round(cor(log(niva_predict$toc_2019),niva_predict$fit),2)), x = 2, y = -0.2)+
  geom_abline(slope  = 1, intercept = 0, col = "red")+
  theme_minimal(base_size = 8)
ggsave(filename = "NIVA_test/niva-test-result.png", dpi = "retina", width = 8, height = 10, units = "cm")
```

```{r maps-toc-predictions, eval=F}
wr.sf.95 <- readRDS("WR/wr.sf.95.rds")
niva_predict <- readRDS("NIVA_test/niva_predict.rds")

nor <- st_read("Country_shapefile/norway.shp") %>% st_transform(st_crs(wr.sf.95))
mypal <- brewer.pal(9, name = "RdBu")
lims.toc <- c(min(c(log(niva_predict$toc_2019), niva_predict$fit)), max((c(log(niva_predict$toc_2019), niva_predict$fit))))
  
diff.niva <- ggplot() + geom_sf(data = nor, fill = "white", col = "lightgray")+
  geom_sf(data = niva_predict, aes(fill = diffLogTOC, col = diffLogTOC)) + 
  scale_color_gradient2(low = mypal[1],high = mypal[9], mid = mypal[5], midpoint = 0, aesthetics = c("colour","fill"), name = "Difference between\nobserved and predicted log(TOC)\nwith NDVI, Bogs, logRunoff and TNdep ") +
  labs(x = "", y = "",subtitle = "b)") +
  theme_minimal(base_size = 8) +
  theme(legend.position = "bottom")
ggsave(plot = diff.niva, filename = "NIVA_test/diff.niva.png", dpi = "retina", width = 8, height = 10, units = "cm")
  
fitted.niva <- ggplot() +  geom_sf(data = nor, fill = "white", col = "lightgray")+
  geom_sf(data = niva_predict, aes(fill = fit, col = fit)) + 
scale_color_gradient2(low = mypal[1],high = mypal[1], mid = mypal[9], midpoint = 0, name = "Fitted log(TOC)", aesthetics = c("fill","col"), limits = lims.toc)+
  labs(x = "", y = "")+
  theme_minimal(base_size = 8)+
  theme(legend.position = "bottom")

ggsave(plot = fitted.niva, filename =  "NIVA_test/fitted.niva.png",dpi = "retina", width = 8, height = 10, units = "cm")

obs.niva <- ggplot() + geom_sf(data = nor, fill = "white", col = "lightgray") +
  geom_sf(data = niva_predict, aes(fill = log(toc_2019), col = log(toc_2019))) + 
 scale_color_gradient2(low = mypal[9],high = mypal[1], mid = mypal[5], midpoint = 0, name = "Sampled log(TOC)", aesthetics = c("fill","col"), limits = lims.toc)+
  labs(x = "", y = "")+
  theme_minimal(base_size = 8)+
  theme(legend.position = "bottom")

ggsave(plot = obs.niva, filename = "NIVA_test/obs.niva.png",dpi = "retina", width = 8, height = 10, units = "cm", device = "png")
```

```{r include-maps, fig.dim = c(16,20)}
listgrob <- list("NIVA_test/obs.niva.png", "NIVA_test/fitted.niva.png", "NIVA_test/diff.niva.png") %>% lapply(readPNG) %>% lapply(rasterGrob)
grid.arrange(grobs = listgrob, ncol = 2, nrow = 2)
```

The difference between model results and observations is computed as $ln([TOC]_{obs})-ln([TOC]_{fit})$. 
# TOC prediction with LM

The LM is then applied to the 2019-dataset.

```{r predict-toc-lm, eval = F}
lm.model <- readRDS("lm.fennoscandia.5.rds")
niva_final <- readRDS("NIVA_test/niva_final.rds")

fm <- logTOC~NDVI+logRunoff+Bog+Arable+TNdep

niva_fit <- predict(lm.model, newdata = niva_final)

niva_predict <- cbind(niva_final, niva_fit)
niva_predict$diffTOC <- niva_predict$toc_2019 - exp(niva_predict$niva_fit)

niva_predict$diffLogTOC <- log(niva_predict$toc_2019) - niva_predict$niva_fit

saveRDS(niva_predict,"NIVA_test/niva_predict_lm.rds")
```

```{r plot-model-results-lm}
niva_predict <- readRDS("NIVA_test/niva_predict_lm.rds")

ggplot(niva_predict) + geom_point(aes(x = log(toc_2019), y = niva_fit))+
  labs(x = "log(TOC 2019)", y = "Predicted log(TOC)")+
  annotate(geom = "label", label = paste("r = ", round(cor(log(niva_predict$toc_2019),niva_predict$niva_fit),2)), x = 2, y = -0.2)+
  geom_abline(slope  = 1, intercept = 0, col = "red")+
  theme_minimal(base_size = 8)
ggsave(filename = "NIVA_test/niva-lm-result.png", dpi = "retina", width = 8, height = 10, units = "cm")
```

```{r maps-toc-predictions-lm, eval=F}
wr.sf.95 <- readRDS("WR/wr.sf.95.rds")
niva_predict <- readRDS("NIVA_test/niva_predict_lm.rds")

nor <- st_read("Country_shapefile/norway.shp") %>% st_transform(st_crs(wr.sf.95))
mypal <- brewer.pal(9, name = "RdYlGn")
lims.toc <- c(min(c(log(niva_predict$toc_2019), niva_predict$fit)), max((c(log(niva_predict$toc_2019), niva_predict$fit))))
  
diff.niva <- ggplot() + geom_sf(data = nor, fill = "white", col = "lightgray")+
  geom_sf(data = niva_predict, aes(fill = diffLogTOC, col = diffLogTOC)) + 
  scale_color_gradient2(low = mypal[9],high = mypal[1], mid = mypal[5], midpoint = 0, name = "Difference between\nobserved and predicted log(TOC)\nwith NDVI, Bogs, logRunoff and TNdep ", aesthetics = c("fill","col"))+
  labs(x = "", y = "")+
  theme_minimal(base_size = 6)+
  theme(legend.position = "bottom")
ggsave(plot = diff.niva, filename = "NIVA_test/diff.niva.lm.png", dpi = "retina", width = 8, height = 10, units = "cm")
  
fitted.niva <- ggplot() +  geom_sf(data = nor, fill = "white", col = "lightgray")+
  geom_sf(data = niva_predict, aes(fill = niva_fit, col = niva_fit)) + 
scale_color_gradient2(low = mypal[9],high = mypal[1], mid = mypal[5], midpoint = 0, name = "Fitted log(TOC)", aesthetics = c("fill","col"), limits = lims.toc)+
  labs(x = "", y = "")+
  theme_minimal(base_size = 6)+
  theme(legend.position = "bottom")

ggsave(plot = fitted.niva, filename =  "NIVA_test/fitted.niva.lm.png",dpi = "retina", width = 8, height = 10, units = "cm")

obs.niva <- ggplot() + geom_sf(data = nor, fill = "white", col = "lightgray") +
  geom_sf(data = niva_predict, aes(fill = log(toc_2019), col = log(toc_2019))) + 
 scale_color_gradient2(low = mypal[9],high = mypal[1], mid = mypal[5], midpoint = 0, name = "Sampled log(TOC)", aesthetics = c("fill","col"), limits = lims.toc)+
  labs(x = "", y = "")+
  theme_minimal(base_size = 6)+
  theme(legend.position = "bottom")

ggsave(plot = obs.niva, filename = "NIVA_test/obs.niva.lm.png",dpi = "retina", width = 8, height = 10, units = "cm", device = "png")
```

```{r include-maps-lm, fig.dim = c(16,20)}
listgrob <- list("NIVA_test/obs.niva.lm.png", "NIVA_test/fitted.niva.lm.png", "NIVA_test/diff.niva.lm.png") %>% lapply(readPNG) %>% lapply(rasterGrob)
grid.arrange(grobs = listgrob, ncol = 2, nrow = 2)
```

The difference between model results and observations is computed as $ln([TOC]_{obs})-ln([TOC]_{fit})$. 
