---
title: "Space for time modelling of TOC concentration"
author: "Camille M. Crapart"
date: "29 9 2021"
output: 
  bookdown::html_document2:
    code_folding: hide
    toc: true
    toc_float: true
    number_sections: true
    fig_caption: true
bibliography: C:\\Users\\raine\\Documents\\UiO\\Bibtex\\Finstad.bib
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, message = F, warning = F, error = F, fig.align = "center")
options(knitr.kable.NA="", knitr.kable.format ="html")
```
```{r library}
library(dplyr)
library(tibble)

library(DBI)
library(sf)
library(gimms)

library(ncdf4)
library(rgdal)

library(stringr)
library(ggplot2)
library(cowplot)
library(spdep)
library(spatialreg)

library(kableExtra)

source("f_plotspatial.R")
fennoscandia <- readRDS("fennoscandia.Rdata")
fennoscandia.spdf <- readRDS("fennoscandia.spdf.Rdata")
norge <- fennoscandia %>% filter(nation == "Norway")

```

# Introduction

In boreal lakes, acid rains led to the acidification of the surface waters @Menz2004. Long-range transport of pollutants was first reported by Brøgger in Naturen in 1880. Then Dannevig in 1959 observed that acidification of water could lead to the death of fishes. In the 70s, Odén showed that the acidification of surface water in Norway originated from air pollution in the UK and in central Europe. Several studies emerged in order to follow-up the quality of surface water in Fennoscandia. A first regional study was conducted in 1986. It showed that most lakes had low ionic concentration, including nutrient concentration like nitrogen and phosphorus. It highlighted the gradient of precipitation and forested areas between the west of Norway and the east of Finland.  Between the period 76-85 and the period 95-2001, acid rains have been reduced by 50% @Menz2004. However, NOx deposition has decreased much less, due to the continued used of ammonia as a fertilizer. As a result, the pH of the lakes began to rise again. Reduced acidification affects the solubility of DOC @Finstad2016, therefore reducing the transport from terrestrial pools to lakes. This led to less dissolution of aluminium from bedrocks, and therefore less flocculation of TOC. Therefore, the TOC concentration in lakes began to rise as well.

The second sulfur protocol was signed in Oslo in 1994. It aimed at limiting sulfur and nitrogen concentrations under new critical loads. Therefore, new data collection was needed to establish an up-to-date reference dataset for the follow up of this protocol. This survey included Norway, Sweden, Finland, Denmark, as well as Scotland, Wales and Russian Kola and Karelia. A larger survey was conducted in including the Northern European Lake Survey in 1995 @Henriksen1998. It included a lot of variables, such as pH, conductivity, major ion concentrations, labile and non-labile Al. The study showed an increasing gradient from west to east. This reflects the presence of thin soil, poorly vegetated areas, and high runoff in western Norway, contrasting with the forests with thick soils and low runoff in the east. 


Based on this survey, Larsen et al. @Larsen2011 modelled the concentration of TOC with NDVI, bogs and runoff as independent variables. They obtained a strong positive effect of NDVI and bogs, but a negative effect of runoff. They used a linear regression and obtained an R-squared of 0,82, showing that these 3 variables were good predictors of the TOC concentration in lakes. However they did not take into account the spatial autocorrelation of the variables. De Wit et al. @DeWit2016a also observed a global increase of TOC in all of Scandinavia, but estimated that a 10% increase in precipitation would lead to an increased mobilization of DOC from the soil and therefore an increased concentrtion of DOC in lakes. However, they suggested that increased precipitation would have a stronger positive in effect in dry places compared to wet places.

90% of TOC in boreal lakes is DOC source @Larsen2011a. It has several roles in the lake ecosystem, being the main source of food for heterotrophic bacteria. In addition, the sunlight is absorbed by the coloured DOC, warming the upper layer of the lakes in turn. Increasing DOC concentration can turn the lake from a net autotrophic balance to a net heterotrophic balance. The concentration of TOC in lakes is therfore a key proxy to estimate carbon fluxes from freshwater to the atmosphere, a flux often underestimated @Natchimuthu2016. 


We decided to extend the model over the full gradient western Norway – eastern Finland. We used the same explanatory parameters as Larsen et al. but we implemented a spatial error model to include the spatial autocorrelation effect. 

  
  
# Methods

## Data preparation
See data preparation

## Models
Description of models used

## Effect size {#effect-size}

The effect size of each independent variable is expressed as the relative change of TOC depending on a given change of the independent variable. The conversion from model estimate to effect size is detailed below.

* x is the independent variable
* $\hat{\theta}$ is the regression coefficient estimate
* $h(\hat{\theta})$ is the effect size


For the non-transformed independent variables (NDVI, slope, percentage of bogs and arable land, N-deposition), the effect size was calculated taking into account that the dependent variable was logged. 

$$
\log([TOC]_1) = \hat{\theta} x_1 \\
\log([TOC]_2) = \hat{\theta} x_2 \\
\log([TOC]_2) - \log([TOC]_1) = \hat{\theta}  (x_2 - x_1) \\
\log([TOC]_2/[TOC]_1) = \hat{\theta} (\Delta x) \\
\frac{[TOC]_2}{[TOC]_1} = 10^{\hat{\theta} \Delta x }
$$


 The delta used for NDVI, bogs and arable land was 0.1 (NDVI is indicated on a scale from 0 to 1 and "bogs" and "arable" are proportions). The delta used for slope and temperature is 1, so the effect size is calculated for an increase of 1 degree. Therefore the effect size for NDVI, bogs and arable land is: 

$$
h(\hat{\theta}) = 10^{\hat{\theta} \times 0.1}
$$

The effect size for slope and temperature is:

$$
h(\hat{\theta}) = 10^{\hat{\theta} \times 1}
$$

The evaluation of the standard error is based on the delta method @MacKenzie2018.

$$ 
Var(h(\hat{\theta})) = \left( \frac{\delta h(\theta)}{\delta \hat{\theta}} \right) ^2 \times Var(\hat{\theta}) \\
Std(h(\hat{\theta})) = \sqrt{\left( \frac{\delta h(\theta)}{\delta \hat{\theta}} \right) ^2 \times Var(\hat{\theta})} \\
Std(h(\hat{\theta})) = \frac{\delta h(\hat{\theta})}{\delta \hat{\theta}} \times Std(\hat{\theta}) \\
\frac{\delta h(\hat{\theta})}{\delta \hat{\theta}} = ln(10) \times 10^{\hat{\theta} \times 0.1} \times 0.1 \\
Std(h(\hat{\theta})) = 0.1 \times ln(10) \times 10^{\hat{\theta} \times 0.1} \times Std(\hat{\theta})
$$


The effect size for the logged variables was calculated as the relative change of TOC concentration for a 10% increase of the independent variable. 

$$
\log([TOC]_1) = \hat{\theta} \times \log(x) \\
\log([TOC]_2) = \hat{\theta} \times \log(x \times 1.1) = \hat{\theta} \times \log(x) + \hat{\theta} \times \log(1.1)\\
\log([TOC]_2) - \log([TOC]_1) = \hat{\theta} \times \log(1.1) \\
\log([TOC]_2/[TOC]_1) = \hat{\theta} \times \log(1.1) = \log(1.1^{\hat{\theta}}) \\
\frac{[TOC]_2}{[TOC]_1} = 1.1^{\hat{\theta}}
$$

The corresponding standard error is: 

$$
Var(h(\hat{\theta})) = \left( \frac{\delta h(\theta)}{\delta \hat{\theta}} \right) ^2 \times Var(\hat{\theta})\\
Std(h(\hat{\theta})) = \sqrt{ \left( \frac{\delta h(\hat{\theta})}{\delta \hat{\theta}} \right) ^2 \times Var(\hat{\theta})}\\
Std(h(\hat{\theta})) = \frac{\delta h(\hat{\theta})}{\delta \hat{\theta}} \times Std(\hat{\theta}) \\
\frac{\delta h(\hat{\theta})}{\delta \hat{\theta}} = 1.1^{\hat{\theta}} \times ln(1.1) \times 0.1 \times 1 \\ 
Std(h(\hat{\theta})) = 1.1^{\hat{\theta}} \times ln(1.1) \times 0.1 \times 1 \times Std(\hat{\theta}) \\
$$


# Results

## Overview of variables

### Mapping of dependent and independent variables

```{r map-variable, fig.dim = c(10,13)}
m <- c("log.toc","ndvi","log.runoff","log.prec","slope","temp","bogs","arable","tndep")
u <- c("TOC concentration, log(mg/L)", "NDVI on scale 0 to 1", "Mean runoff, log(kg/m2/an)","Mean annual precipitation,\n log(mm)","Slope in degrees","Mean annual temperature,\n degree celsius","Proportion of bogs, %","Proportion of\narable land, %","Total nitrogen\ndeposition, ug/m2")
list.map <- lapply(m,FUN = function(x)  f_plotspatial(data=fennoscandia,var=fennoscandia[[x]],plottitle = "")+annotate("text", x = 10, y = 69.5, label = paste(u[grep(x,m)],"\n(",x,")",sep="")))

cowplot::plot_grid(plotlist = list.map,ncol=2)
```

### Correlation between independant variables

```{r corrplot, fig.cap = "Correlation plot of independent variables"}
cor.mat <- cor(dplyr::select(fennoscandia,m[-1]))
corrplot::corrplot(cor.mat, method = "number",type = "lower")
```

### Spatial autocorrelation & VIF

The spatial autocorrelation of the independent variables is evaluated thanks to the Moran's I index. X is the variable of interest, N the number of spatial units, and w_ij a diagonal weight matrix.

$$
I = \frac{N}{\Sigma_i \Sigma_j w_{ij}} \frac{\Sigma_i \Sigma_j w_{ij} (X_i-\bar{X})(X_j-\bar{X})}{\Sigma_i (X_i-\bar{X})^2}
$$

Moreover, the collinearity between the independent variables is assessed by using the Variance Inflation Factor (VIF). It is obtained by regressing each independent variables towards the others, and calculated using the resulting $R^2$.  

$$
VIF = \frac{1}{1-R_i^2}
$$

```{r neighbour-matrix,  eval = F}
library(spdep)
k.neigh.set <- knearneigh(fennoscandia.spdf, k = 100)
k.neigh.nb.set <- knn2nb(k.neigh.set)
k.neigh.w <- nb2listw(k.neigh.nb.set)
saveRDS(k.neigh.w,"k.neigh.w.Rdata")
```

```{r spatial-autocorrelation, eval = T}
k.neigh.w <- readRDS("k.neigh.w.Rdata")
moran.list <- c() 

m <- c("log.toc","ndvi","log.runoff","log.prec","slope","temp","bogs","arable","tndep")

for (i in m){
  moran.list[[i]] <- moran.test(fennoscandia[,i],k.neigh.w, na.action = na.omit, alternative = "two.sided")
}

moran.df <- data.frame(m) %>% setNames("parameter")
moran.df$moran.I <- NA
moran.df$p.value <- NA

for (i in 1:length(moran.list)){
  moran.df$moran.I[i] <- moran.list[[i]]$estimate[1]
  moran.df$p.value[i] <- moran.list[[i]]$p.value
}

saveRDS(moran.df,"moran.df.Rdata")
```

```{r vif}
lm.all <- lm(data = fennoscandia, formula = as.formula(paste(m[1],"~",paste(m[-1],collapse = "+"))))
lm.vif <- car::vif(lm.all) %>% as.data.frame() %>% setNames("VIF")
```

```{r moran-vif-table}
moran.df <- readRDS("moran.df.Rdata")

moran.limit <- 1/(dim(fennoscandia)[1]-1)

moran.vif.df <- merge(moran.df,lm.vif, by.x = "parameter", by.y = 0)
moran.vif.df[,2:4] <- round(moran.vif.df[,2:4],2)

moran.vif.df[,-3] %>% 
  dplyr::mutate(
    VIF = cell_spec(VIF,color = ifelse(VIF > 3,"red", "black"), bold = ifelse(VIF > 5, T, F)),
    moran.I = cell_spec(moran.I,bold = ifelse(moran.I > moran.limit, T, F),color = ifelse(moran.I > 0.8, "red","black"))) %>%
  knitr::kable(digits = 2, 
    caption = paste("Moran'I of dependant and independant variable (limit = ",
    format(moran.limit,scientific = T, digits = 2),")",sep = ""),
    escape = F) %>%    
  kable_styling(bootstrap_options = "bordered")
        
```
The most auto-correlated variables (precipitation, temperature, and N deposition) are also the ones with the highest VIF. Temperature has a VIF higher than 5 and was highly correlated to N-deposition (Figure \@ref(fig:corrplot)). Log.prec also has a high VIF value (`r round(lm.vif["log.prec",],2)`) and a high correlation with log.runoff


## Comparison of linear model and spatial error model for the Fennoscandian dataset 

An ordinary least square regression (OLS) and a Spatial Error Model (SEM) were fitted for the log.toc against the selected independent variables. The Spatial Error Model takes into account the spatial autocorrelation of the independent variables in the error term of the regression. To compare the two models, the Akaike Information Criterion was calculated.

Both models were fitted with and without scaled variables. The effect size calculated using the raw (non-scaled) coefficients according to the method explained in \@ref(effect-size). A comparison of the regression coefficients and effect size for each independent variables is shown on figure \@ref(fig:compare-plots-1). 

```{r ols-fennoscandia, results = T}
k.neigh.w <- readRDS("k.neigh.w.Rdata")

fm.s <- s.log.toc~s.ndvi+s.log.runoff+s.slope+s.bogs+s.arable+s.tndep
s.lm.fennoscandia <- lm(fm.s, data = fennoscandia, na.action = na.exclude)

fm <- log.toc~ndvi+log.runoff+slope+bogs+arable+tndep
lm.fennoscandia <- lm(fm, data = fennoscandia, na.action = na.exclude)

s.lm.r2 <- summary(s.lm.fennoscandia)$adj.r.squared
s.moran.I.res.lm <- lm.morantest(s.lm.fennoscandia, k.neigh.w, alternative = "two.sided")

lm.r2 <- summary(lm.fennoscandia)$adj.r.squared
moran.I.res.lm <- lm.morantest(lm.fennoscandia, k.neigh.w, alternative = "two.sided")

moran.limit.fennoscandia <- 1/(dim(fennoscandia)[1]-1)

s.lm.coef <- summary(s.lm.fennoscandia)$coefficients %>% as.data.frame()
s.lm.coef <- s.lm.coef[-1,] %>% rownames_to_column(var = "Parameter")

lm.coef <- summary(lm.fennoscandia)$coefficients %>% as.data.frame()
lm.coef <- lm.coef[-1,] %>% rownames_to_column(var = "Parameter")

lm.effectsize <- lm.coef[,1:3]

n <- length(lm.coef$Parameter)
m <- lm.coef$Parameter

for(i in 1:n){
  if(grepl("log",m[i])==T){
    lm.effectsize[i,2] <- 1.1^(lm.coef[i,2])
    lm.effectsize[i,3] <- 1.1^(lm.coef[i,2])*log(1.1)*lm.coef[i,3]
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    lm.effectsize[i,2] <- 10^(lm.coef[i,2]*0.1)
    lm.effectsize[i,3] <- 0.1*log(10)*10^(lm.coef[i,2]*0.1)*lm.coef[i,3]
  }else if(m[i] %in% c("slope","temp")){
    lm.effectsize[i,2] <- 10^(lm.coef[i,2]*1)
    lm.effectsize[i,3] <- 1*log(10)*10^(lm.coef[i,2]*1)*lm.coef[i,3]
  }else if(m[i] %in% c("tndep")){
    lm.effectsize[i,2] <- 10^(lm.coef[i,2]*100)
    lm.effectsize[i,3] <- 100*log(10)*10^(lm.coef[i,2]*100)*lm.coef[i,3]
  }
}

lm.effectsize$Percent <- 100*(lm.effectsize$Estimate-1)

```

```{r arm-sim-test-lm}
sm.fennoscandia <- arm::sim(lm.fennoscandia,n.sims = 100)

sm.coef <- sm.fennoscandia@coef[,-1]
sm.effectsize <- data.frame(parameter = colnames(sm.coef), effect.size = NA, std.error = NA)

n <- dim(sm.coef)[2]
m <- colnames(sm.coef)

for(i in 1:n){
  if(grepl("log",m[i])==T){
    sm.effectsize[i,2] <- mean(1.1^(sm.coef[,i]))
    sm.effectsize[i,3] <- sd(1.1^(sm.coef[,i])*log(1.1)*sm.coef[,i])
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    sm.effectsize[i,2] <- mean(10^(sm.coef[,i]*0.1))
    sm.effectsize[i,3] <- sd(0.1*log(10)*10^(sm.coef[,i]*0.1)*sm.coef[,i])
  }else if(m[i] %in% c("slope","temp")){
    sm.effectsize[i,2] <- mean(10^(sm.coef[,i]*1))
    sm.effectsize[i,3] <- sd(1*log(10)*10^(sm.coef[,i]*1)*sm.coef[,i])
  }else if(m[i] %in% c("tndep")){
    sm.effectsize[i,2] <- mean(10^(sm.coef[,i]*100))
    sm.effectsize[i,3] <- sd(100*log(10)*10^(sm.coef[,i]*100)*sm.coef[,i])
  }
}

```

```{r summary-table-lm}
summary.table.lm <- cbind(dplyr::select(lm.coef,Parameter),s.lm.coef[,2:3],lm.coef[,2:3],lm.effectsize[,2:4],sm.effectsize[,2:3]) %>%
                rbind(c("AIC",AIC(s.lm.fennoscandia),"",AIC(lm.fennoscandia),"","","","","","")) %>%
                rbind(c("R2",s.lm.r2,"",lm.r2,"","","","","","")) %>%
                rbind(c("Moran'I res",s.moran.I.res.lm$estimate[[1]],"",moran.I.res.lm$estimate[[1]],"","","","","",""))
summary.table.lm[,-1] <- apply(summary.table.lm[,-1],2,as.numeric)

```

```{r sem, eval = F}
k.neigh.w <- readRDS("k.neigh.w.Rdata")

lagrange <- lm.LMtests(lm.fennoscandia,k.neigh.w,test = c("LMerr","LMlag","RLMerr","RLMlag"))

fm.s <- s.log.toc~s.ndvi+s.log.runoff+s.slope+s.bogs+s.arable+s.tndep
s.sem.fennoscandia <- errorsarlm(fm.s,fennoscandia,k.neigh.w)
saveRDS(s.sem.fennoscandia,"s.sem.fennoscandia.Rdata")

fm <- log.toc~ndvi+log.runoff+slope+bogs+arable+tndep
sem.fennoscandia <- errorsarlm(fm,fennoscandia,k.neigh.w)
saveRDS(sem.fennoscandia,"sem.fennoscandia.Rdata")
```

```{r sem-results}
s.sem.fennoscandia <- readRDS("s.sem.fennoscandia.Rdata")
sem.fennoscandia <- readRDS("sem.fennoscandia.Rdata")
k.neigh.w <- readRDS("k.neigh.w.Rdata")


s.sem.coef <- s.sem.fennoscandia$coefficients[-1] %>% as.data.frame() %>% 
              setNames("Estimate")
s.sem.coef <- s.sem.coef %>% rownames_to_column(var = "Parameter")
s.sem.coef$std.error <- s.sem.fennoscandia$rest.se[-1]

sem.coef <- sem.fennoscandia$coefficients[-1] %>% as.data.frame() %>% 
              setNames("Estimate")
sem.coef <- sem.coef %>% rownames_to_column(var = "Parameter")
sem.coef$std.error <- sem.fennoscandia$rest.se[-1]

sem.effectsize <- sem.coef[,1:3]

n <- length(sem.coef$Parameter)
m <- sem.coef$Parameter

for(i in 1:n){
  if(grepl("log",m[i])==T){
    sem.effectsize[i,2] <- 1.1^(sem.coef[i,2])
    sem.effectsize[i,3] <- 1.1^(sem.coef[i,2])*log(1.1)*sem.coef[i,3]
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    sem.effectsize[i,2] <- 10^(sem.coef[i,2]*0.1)
    sem.effectsize[i,3] <- 0.1*log(10)*10^(sem.coef[i,2]*0.1)*sem.coef[i,3]
  }else if(m[i] %in% c("slope","temp")){
    sem.effectsize[i,2] <- 10^(sem.coef[i,2]*1)
    sem.effectsize[i,3] <- 1*log(10)*10^(sem.coef[i,2]*1)*sem.coef[i,3]
  }else if(m[i] %in% c("tndep")){
    sem.effectsize[i,2] <- 10^(sem.coef[i,2]*100)
    sem.effectsize[i,3] <- 100*log(10)*10^(sem.coef[i,2]*100)*sem.coef[i,3]
  }
}

sem.effectsize$Percent <- 100*(sem.effectsize$Estimate-1)

s.sem.AIC <- 2*(n-1)-2*s.sem.fennoscandia$LL
sem.AIC <- 2*(n-1)-2*sem.fennoscandia$LL

s.moran.I.res.sem <- moran.test(s.sem.fennoscandia$residuals, k.neigh.w, alternative = "two.sided")

moran.I.res.sem <- moran.test(sem.fennoscandia$residuals, k.neigh.w, alternative = "two.sided")

summary.table.sem <- cbind(dplyr::select(sem.coef,Parameter),s.sem.coef[,2:3],sem.coef[,2:3],sem.effectsize[,2:4]) %>%
                rbind(c("AIC",s.sem.AIC,"",sem.AIC,"","","","")) %>%
                rbind(c("Moran'I res", s.moran.I.res.sem$estimate[[1]],"", moran.I.res.sem$estimate[[1]], "","","",""))
summary.table.sem[,-1] <- apply(summary.table.sem[,-1],2,as.numeric)

```

```{r compare-estimates}
n <- c(names(s.sem.coef),"model")
m <- cbind.data.frame(s.lm.coef[,1:3],model = "LM") %>% setNames(n)
o <- cbind.data.frame(s.sem.coef,model = "SEM")
  
scaled.df <- rbind(m,o)

scaled.plot <- ggplot(scaled.df, aes(group = model))+geom_col(aes(x=Estimate,y=Parameter, fill = model), position = "dodge", width = 0.5)+
  geom_errorbar(aes(y=Parameter,xmin = Estimate-std.error,xmax=Estimate+std.error), position = "dodge", width = 0.5)+
  labs(x = "Scaled Estimate", y = "Independent variable", subtitle = paste("LM: AIC =",round(AIC(s.lm.fennoscandia),2),"; Moran's I = ",round(s.moran.I.res.lm$estimate[[1]],2),"\nSEM: AIC =",round(s.sem.AIC,2),"; Moran's I =",round(s.moran.I.res.sem$estimate[[1]],2)))+
  theme_bw()+theme(legend.position = "none")
  
```

```{r compare-effect-size}

n <- c(names(sem.effectsize),"model")
m <- cbind.data.frame(lm.effectsize,model = "LM") %>% setNames(n)
o <- cbind.data.frame(sem.effectsize,model = "SEM")
  
h.df <- rbind(m,o)

effectsize.plot <- ggplot(h.df, aes(group = model))+
  geom_col(aes(x=Percent,y=Parameter, fill = model), position = "dodge", width = 0.5)+
  geom_errorbar(aes(y=Parameter,xmin = Percent-(100*std.error),xmax=Percent+(100*std.error)), position = "dodge", width = 0.5)+
  labs(x = "Effect size in %", y = "", subtitle = paste("LM: AIC =",round(AIC(lm.fennoscandia),2),"; Moran's I = ",round(moran.I.res.lm$estimate[[1]],2),"\nSEM: AIC =",round(sem.AIC,2),"; Moran's I =",round(moran.I.res.sem$estimate[[1]],2)))+
  theme_bw()

```

**Reminder: the effect size is expressed as % change of TOC concentration for:**

**- 10% increase of runoff**

**- 0.1 unit increase of NDVI, bogs and arable land**

**- 1 degree increase of slope**

**- 100 ug increase of nitrogen deposition.**

```{r compare-plots-1, fig.dim = c(8,4), fig.cap = "Comparison of OLS and SEM models"}
cowplot::plot_grid(plotlist = list(scaled.plot,effectsize.plot),ncol=2)

```

## Simplified models on Norway and Fennoscandia

In order to compare the results of this study to the results of Larsen et al. (@Larsen2011), we fitted two simpler models using only three predictors: NDVI, proportion of bogs and runoff. OLS and SEM models were fitted for the entire dataset as well as for the norwegian subset.The scaled estimates and the effect size were calculated similarly to the previous section.

### Simple models for Norway

```{r kmat, eval = F}
norge.spdf <- SpatialPointsDataFrame(norge[,c("longitude","latitude")],norge)

norge.kmat <- norge.spdf %>% knearneigh(k=50) %>% knn2nb %>% nb2listw
saveRDS(norge.kmat,"norge.kmat.Rdata")
```

```{r ols-norge, results = T}
norge.kmat <- readRDS("norge.kmat.Rdata")

fm.s <- s.log.toc~s.ndvi+s.log.runoff+s.bogs
s.lm.norge <- lm(fm.s, data = norge, na.action = na.exclude)

fm <- log.toc~ndvi+log.runoff+bogs
lm.norge <- lm(fm, data = norge, na.action = na.exclude)

s.lm.r2 <- summary(s.lm.norge)$adj.r.squared
s.moran.I.res.lm <- lm.morantest(s.lm.norge, norge.kmat, alternative = "two.sided")

lm.r2 <- summary(lm.norge)$adj.r.squared
moran.I.res.lm <- lm.morantest(lm.norge, norge.kmat, alternative = "two.sided")

moran.limit.norge <- 1/(dim(norge)[1]-1)
  
s.lm.coef <- summary(s.lm.norge)$coefficients %>% as.data.frame()
s.lm.coef <- s.lm.coef[-1,] %>% rownames_to_column(var = "Parameter")

lm.coef <- summary(lm.norge)$coefficients %>% as.data.frame()
lm.coef <- lm.coef[-1,] %>% rownames_to_column(var = "Parameter")

lm.effectsize <- lm.coef[,1:3]

n <- length(lm.coef$Parameter)
m <- lm.coef$Parameter

for(i in 1:n){
  if(grepl("log",m[i])==T){
    lm.effectsize[i,2] <- 1.1^(lm.coef[i,2])
    lm.effectsize[i,3] <- 1.1^(lm.coef[i,2])*log(1.1)*lm.coef[i,3]
  }else if(m[i] %in% c("ndvi","bogs")){
    lm.effectsize[i,2] <- 10^(lm.coef[i,2]*0.1)
    lm.effectsize[i,3] <- 0.1*log(10)*10^(lm.coef[i,2]*0.1)*lm.coef[i,3]
  }
}

lm.effectsize$Percent <- 100*(lm.effectsize$Estimate-1)

summary.table.norge <- cbind(dplyr::select(lm.coef,Parameter),s.lm.coef[,2:3],lm.coef[,2:3],lm.effectsize[,2:4]) %>%
                rbind(c("AIC",AIC(s.lm.norge),"",AIC(lm.norge),"","","","")) %>%
                rbind(c("R2",s.lm.r2,"",lm.r2,"","","","")) %>%
                rbind(c("Moran'I res",s.moran.I.res.lm$estimate[[1]],"",moran.I.res.lm$estimate[[1]],"","","",""))
summary.table.norge[,-1] <- apply(summary.table.norge[,-1],2,as.numeric)

```

```{r sem-simple-norway, eval = F}
norge.kmat <- readRDS("norge.kmat.Rdata")

s.fm <- s.log.toc~s.ndvi+s.log.runoff+s.bogs
s.sem.norge.simple <- errorsarlm(s.fm,norge,norge.kmat)
saveRDS(s.sem.norge.simple,"s.sem.norge.simple.Rdata")

fm <- log.toc~ndvi+log.runoff+bogs
sem.norge.simple <- errorsarlm(fm,norge,norge.kmat)
saveRDS(sem.norge.simple,"sem.norge.simple.Rdata")

```

```{r sem-simple-results-norway}
s.sem.norge.simple <- readRDS("s.sem.norge.simple.Rdata")
sem.norge.simple <- readRDS("sem.norge.simple.Rdata")
k.neigh.w <- readRDS("k.neigh.w.Rdata")

s.sem.coef <- s.sem.norge.simple$coefficients[-1] %>% as.data.frame() %>% 
              setNames("Estimate")
s.sem.coef <- s.sem.coef %>% rownames_to_column(var = "Parameter")
s.sem.coef$std.error <- s.sem.norge.simple$rest.se[-1]

sem.coef <- sem.norge.simple$coefficients[-1] %>% as.data.frame() %>% 
              setNames("Estimate")
sem.coef <- sem.coef %>% rownames_to_column(var = "Parameter")
sem.coef$std.error <- sem.norge.simple$rest.se[-1]

sem.effectsize <- sem.coef[,1:3]

n <- length(sem.coef$Parameter)
m <- sem.coef$Parameter

for(i in 1:n){
  if(grepl("log",m[i])==T){
    sem.effectsize[i,2] <- 1.1^(sem.coef[i,2])
    sem.effectsize[i,3] <- 1.1^(sem.coef[i,2])*log(1.1)*sem.coef[i,3]
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    sem.effectsize[i,2] <- 10^(sem.coef[i,2]*0.1)
    sem.effectsize[i,3] <- 0.1*log(10)*10^(sem.coef[i,2]*0.1)*sem.coef[i,3]
  }else if(m[i] %in% c("slope","temp","tndep")){
    sem.effectsize[i,2] <- 10^(sem.coef[i,2]*1)
    sem.effectsize[i,3] <- 1*log(10)*10^(sem.coef[i,2]*1)*sem.coef[i,3]
  }
}

sem.effectsize$Percent <- 100*(sem.effectsize$Estimate-1)

s.sem.AIC <- 2*(n-1)-2*s.sem.norge.simple$LL
s.moran.I.res.sem <- moran.test(s.sem.norge.simple$residuals, norge.kmat, alternative = "two.sided")

sem.AIC <- 2*(n-1)-2*sem.norge.simple$LL
moran.I.res.sem <- moran.test(sem.norge.simple$residuals, norge.kmat, alternative = "two.sided")

summary.table.sem.norge <- cbind(dplyr::select(sem.coef,Parameter),s.sem.coef[,2:3],sem.coef[,2:3],sem.effectsize[,2:4]) %>%
                rbind(c("AIC",s.sem.AIC,"",sem.AIC,"","","","")) %>%
                rbind(c("Moran'I res", s.moran.I.res.sem$estimate[[1]],"",moran.I.res.sem$estimate[[1]], "","","",""))
summary.table.sem.norge[,-1] <- apply(summary.table.sem.norge[,-1],2,as.numeric)

```

```{r compare-estimates-simple-norway}
n <- c(names(s.sem.coef),"model")
m <- cbind.data.frame(s.lm.coef[,1:3],model = "LM") %>% setNames(n)
o <- cbind.data.frame(s.sem.coef,model = "SEM")
  
scaled.df <- rbind(m,o)

scaled.plot <- ggplot(scaled.df, aes(group = model))+geom_col(aes(x=Estimate,y=Parameter, fill = model), position = "dodge", width = 0.5)+
  geom_errorbar(aes(y=Parameter,xmin = Estimate-std.error,xmax=Estimate+std.error), position = "dodge", width = 0.5)+
  labs(x="Scaled Estimate", y = "Independent variables", subtitle = paste("LM: AIC =",round(AIC(s.lm.norge),2),"; Moran's I = ",round(s.moran.I.res.lm$estimate[[1]],2),"\nSEM: AIC =",round(s.sem.AIC,2),"; Moran's I =",round(s.moran.I.res.sem$estimate[[1]],2)))+
  theme_bw()+
  theme(legend.position = "none")

```

```{r compare-effect-size-simple-norway}

n <- c(names(sem.effectsize),"model")
m <- cbind.data.frame(lm.effectsize,model = "LM") %>% setNames(n)
o <- cbind.data.frame(sem.effectsize,model = "SEM")
  
h.df <- rbind(m,o)

effectsize.plot <- ggplot(h.df, aes(group = model))+
  geom_col(aes(x=Percent,y=Parameter, fill = model), position = "dodge", width = 0.5)+
  geom_errorbar(aes(y=Parameter,xmin = Percent-(100*std.error),xmax=Percent+(100*std.error)), position = "dodge", width = 0.5)+
  labs(x = "Effect size in %", y = "", subtitle = paste("LM: AIC =",round(AIC(lm.norge),2),"; Moran's I = ",round(moran.I.res.lm$estimate[[1]],2),"\nSEM: AIC =",round(sem.AIC,2),"; Moran's I =",round(moran.I.res.sem$estimate[[1]],2)))+
  theme_bw()
```
**Reminder: the effect size is expressed as % change of TOC concentration for:**

**- 10% increase of runoff**

**- 0.1 unit increase of NDVI and bogs.**


```{r compare-plots-2, fig.dim = c(8,4), fig.cap = "Comparison of models for the Norwegian subset"}
cowplot::plot_grid(plotlist = list(scaled.plot,effectsize.plot),ncol=2)

```

### Simplified models for Fennoscandia

```{r simple-ols-fennoscandia, results = T}
k.neigh.w <- readRDS("k.neigh.w.Rdata")

fm.s <- s.log.toc~s.ndvi+s.log.runoff+s.bogs
s.lm.fennoscandia <- lm(fm.s, data = fennoscandia, na.action = na.exclude)

fm <- log.toc~ndvi+log.runoff+bogs
lm.fennoscandia <- lm(fm, data = fennoscandia, na.action = na.exclude)

s.lm.r2 <- summary(s.lm.fennoscandia)$adj.r.squared
s.moran.I.res.lm <- lm.morantest(s.lm.fennoscandia, k.neigh.w, alternative = "two.sided")

lm.r2 <- summary(lm.fennoscandia)$adj.r.squared
moran.I.res.lm <- lm.morantest(lm.fennoscandia, k.neigh.w, alternative = "two.sided")

moran.limit.fennoscandia <- 1/(dim(fennoscandia)[1]-1)

s.lm.coef <- summary(s.lm.fennoscandia)$coefficients %>% as.data.frame()
s.lm.coef <- s.lm.coef[-1,] %>% rownames_to_column(var = "Parameter")

lm.coef <- summary(lm.fennoscandia)$coefficients %>% as.data.frame()
lm.coef <- lm.coef[-1,] %>% rownames_to_column(var = "Parameter")

lm.effectsize <- lm.coef[,1:3]

n <- length(lm.coef$Parameter)
m <- lm.coef$Parameter

for(i in 1:n){
  if(grepl("log",m[i])==T){
    lm.effectsize[i,2] <- 1.1^(lm.coef[i,2])
    lm.effectsize[i,3] <- 1.1^(lm.coef[i,2])*log(1.1)*lm.coef[i,3]
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    lm.effectsize[i,2] <- 10^(lm.coef[i,2]*0.1)
    lm.effectsize[i,3] <- 0.1*log(10)*10^(lm.coef[i,2]*0.1)*lm.coef[i,3]
  }
} 

lm.effectsize$Percent <- 100*(lm.effectsize$Estimate-1)

summary.table.simple.lm <- cbind(dplyr::select(lm.coef,Parameter),s.lm.coef[,2:3],lm.coef[,2:3],lm.effectsize[,2:4]) %>%
                rbind(c("AIC",AIC(s.lm.fennoscandia),"",AIC(lm.fennoscandia),"","","","","","")) %>%
                rbind(c("R2",s.lm.r2,"",lm.r2,"","","","","","")) %>%
                rbind(c("Moran'I res",s.moran.I.res.lm$estimate[[1]],"",moran.I.res.lm$estimate[[1]],"","","","","",""))
summary.table.simple.lm[,-1] <- apply(summary.table.simple.lm[,-1],2,as.numeric)

```

```{r sem-simple-fennosandia, eval = F}
k.neigh.w <- readRDS("k.neigh.w.Rdata")

s.fm <- s.log.toc~s.ndvi+s.log.runoff+s.bogs
s.sem.fen.simple <- errorsarlm(s.fm,fennoscandia,k.neigh.w)
saveRDS(s.sem.fen.simple,"s.sem.fen.simple.Rdata")

fm <- log.toc~ndvi+log.runoff+bogs
sem.fen.simple <- errorsarlm(fm,fennoscandia,k.neigh.w)
saveRDS(sem.fen.simple,"sem.fen.simple.Rdata")

```

```{r sem-simple-results}
s.sem.fen.simple <- readRDS("s.sem.fen.simple.Rdata")
sem.fen.simple <- readRDS("sem.fen.simple.Rdata")
k.neigh.w <- readRDS("k.neigh.w.Rdata")

s.sem.coef <- s.sem.fen.simple$coefficients[-1] %>% as.data.frame() %>% 
              setNames("Estimate")
s.sem.coef <- s.sem.coef %>% rownames_to_column(var = "Parameter")
s.sem.coef$std.error <- s.sem.fen.simple$rest.se[-1]

sem.coef <- sem.fen.simple$coefficients[-1] %>% as.data.frame() %>% 
              setNames("Estimate")
sem.coef <- sem.coef %>% rownames_to_column(var = "Parameter")
sem.coef$std.error <- sem.fen.simple$rest.se[-1]

sem.effectsize <- sem.coef[,1:3]

n <- length(sem.coef$Parameter)
m <- sem.coef$Parameter

for(i in 1:n){
  if(grepl("log",m[i])==T){
    sem.effectsize[i,2] <- 1.1^(sem.coef[i,2])
    sem.effectsize[i,3] <- 1.1^(sem.coef[i,2])*log(1.1)*sem.coef[i,3]
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    sem.effectsize[i,2] <- 10^(sem.coef[i,2]*0.1)
    sem.effectsize[i,3] <- 0.1*log(10)*10^(sem.coef[i,2]*0.1)*sem.coef[i,3]
  }
}

sem.effectsize$Percent <- 100*(sem.effectsize$Estimate-1)

s.sem.AIC <- 2*(n-1)-2*s.sem.fen.simple$LL
s.moran.I.res.sem <- moran.test(s.sem.fen.simple$residuals, k.neigh.w, alternative = "two.sided")

sem.AIC <- 2*(n-1)-2*sem.fen.simple$LL
moran.I.res.sem <- moran.test(sem.fen.simple$residuals, k.neigh.w, alternative = "two.sided")

summary.table.simple.sem <- cbind(dplyr::select(sem.coef,Parameter),s.sem.coef[,2:3],sem.coef[,2:3],sem.effectsize[,2:4]) %>%
                rbind(c("AIC",s.sem.AIC,"",sem.AIC,"","","","")) %>%
                rbind(c("Moran'I res", s.moran.I.res.sem$estimate[[1]],"",moran.I.res.sem$estimate[[1]], "","","",""))
summary.table.simple.sem[,-1] <- apply(summary.table.simple.sem[,-1],2,as.numeric)

```

```{r compare-estimates-simple-fen}
n <- c(names(s.sem.coef),"model")
m <- cbind.data.frame(s.lm.coef[,1:3],model = "LM") %>% setNames(n)
o <- cbind.data.frame(s.sem.coef,model = "SEM")
  
scaled.df <- rbind(m,o)

scaled.plot <- ggplot(scaled.df, aes(group = model))+geom_col(aes(x=Estimate,y=Parameter, fill = model), position = "dodge", width = 0.5)+
  geom_errorbar(aes(y=Parameter,xmin = Estimate-std.error,xmax=Estimate+std.error), position = "dodge", width = 0.5)+
  labs(x = "Scaled estimates",y = "Independent variables", subtitle = paste("LM: AIC =",round(AIC(s.lm.fennoscandia),2),"; Moran's I = ",round(s.moran.I.res.lm$estimate[[1]],2),"\nSEM: AIC =",round(s.sem.AIC,2),"; Moran's I =",round(s.moran.I.res.sem$estimate[[1]],2)))+
  theme_bw()+
  theme(legend.position = "none")

```

```{r compare-effect-size-simple-fen}

n <- c(names(sem.effectsize),"model")
m <- cbind.data.frame(lm.effectsize,model = "LM") %>% setNames(n)
o <- cbind.data.frame(sem.effectsize,model = "SEM")
  
h.df <- rbind(m,o)

effectsize.plot <- ggplot(h.df, aes(group = model))+
  geom_col(aes(x=Percent,y=Parameter, fill = model), position = "dodge", width = 0.5)+
  geom_errorbar(aes(y=Parameter,xmin = Percent-(100*std.error),xmax=Percent+(100*std.error)), position = "dodge", width = 0.5)+
  labs(x = "Effect size in %", y = "", subtitle = paste("LM: AIC =",round(AIC(lm.fennoscandia),2),"; Moran's I = ",round(moran.I.res.lm$estimate[[1]],2),"\nSEM: AIC =",round(sem.AIC,2),"; Moran's I =",round(moran.I.res.sem$estimate[[1]],2)))+
  theme_bw()
```
**Reminder: the effect size is expressed as % change of TOC concentration for:**

**- 10% increase of runoff**

**- 0.1 unit increase of NDVI and bogs.**


```{r compare-plots-3, fig.dim = c(8,4), fig.cap = "Comparison of simplified models for Fennoscandia"}
cowplot::plot_grid(plotlist = list(scaled.plot,effectsize.plot),ncol=2)
```

### Geographically Weighted Regression 

A geographically weighted model was fitted on the Fennoscandian dataset. The objective is to examine the regional relationship with the dependent and independent variables. A geographically weighted model computes a linear regression giving a stronger weight to the closest neighbours. The neighbours here are choosen to be the 500 nearest lakes, where weight for each lake is attributed following a gaussian distribution. The local regression coefficients are shown on \@ref(fig:gwr-results)

```{r GWR-fennoscandia, eval = F}
fm <- log.toc~ndvi+log.runoff+bogs

library(GWmodel)
bw.fennoscandia <- bw.gwr(fm, data = fennoscandia.spdf, kernel = "gaussian", adaptive = T)
gwr.fennoscandia <- gwr.basic(fm, data = fennoscandia.spdf, bw = 500, kernel = "gaussian", adaptive = T)

saveRDS(bw.fennoscandia, "bw.fennoscandia.Rdata")
saveRDS(gwr.fennoscandia, "gwr.fennoscandia.Rdata")
```

```{r gwr-results, fig.dim = c(10,6), fig.cap = "Maps of the GWR coefficients"}
bw.fennoscandia <- readRDS("bw.fennoscandia.Rdata")
gwr.fennoscandia <- readRDS("gwr.fennoscandia.Rdata")
k.neigh.w <- readRDS("k.neigh.w.Rdata")

gwr.coef <- gwr.fennoscandia$SDF@data

m <- c("ndvi","log.runoff","bogs")
n <- length(m)

gwr.effectsize <- gwr.coef[,2:(n+1)]

for(i in 1:n){
  if(grepl("log",m[i])==T){
    gwr.effectsize[i,2] <- 1.1^(gwr.coef[i,2])
#    gwr.effectsize[i,3] <- 1.1^(gwr.coef[i,2])*log(1.1)*gwr.coef[i,3]
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    gwr.effectsize[i,2] <- 10^(gwr.coef[i,2]*0.1)
#    gwr.effectsize[i,3] <- 0.1*log(10)*10^(gwr.coef[i,2]*0.1)*gwr.coef[i,3]
  }else if(m[i] %in% c("slope","temp","tndep")){
    gwr.effectsize[i,2] <- 10^(gwr.coef[i,2]*1)
#    gwr.effectsize[i,3] <- 1*log(10)*10^(gwr.coef[i,2]*1)*gwr.coef[i,3]
  }
}

gwr.effectsize.percent <- 100*(gwr.effectsize)-1

coef.plot <- lapply(m,FUN = function(x)  f_plotspatial(data=fennoscandia,var=gwr.effectsize.percent[[x]],plottitle = x))
coef.plot$toc <- f_plotspatial(fennoscandia,var=gwr.coef$y,plottitle = "Observed toc (log)")
cowplot::plot_grid(plotlist = coef.plot,ncol=2)

gwr.AIC <- gwr.fennoscandia$GW.diagnostic$AICc
gwr.r2 <- gwr.fennoscandia$GW.diagnostic$gwR2.adj
gwr.moran <- moran.test(gwr.coef$Stud_residual,k.neigh.w,alternative = "two.sided")

summary.table.gwr <- data.frame(AIC = gwr.AIC,R2 = gwr.r2,Moran.I =gwr.moran$estimate[[1]])
                                
knitr::kable(summary.table.gwr,digits = 3) %>%
  kable_styling(bootstrap_options = "bordered")
```

# Appendix

## Summary table LM and SEM Fennoscandia

```{r lm-table-results}
knitr::kable(summary.table.lm,digits = 3) %>%
  add_header_above(c("Model"=1,"Scaled LM" = 2, "LM" = 2, "Effect size" = 3,"SIM" = 2),italic = T) %>%
  column_spec(column = 8, bold = T) %>% 
  kable_styling(bootstrap_options = "bordered") %>%
  group_rows(group_label = "Model Evaluation", start_row = n+1,end_row=n+3)

knitr::kable(summary.table.sem,digits = 4) %>%
  add_header_above(c("Model"=1,"Scaled SEM" = 2, "SEM" = 2, "Effect size" = 3),italic = T) %>%
  kable_styling(bootstrap_options = "bordered") %>%
  column_spec(column = 8, bold = T) %>% 
  group_rows(group_label = "Model Evaluation", start_row = n+1,end_row=n+2)
```

## Summary tables simple model Norway

```{r summary-table-norway}

knitr::kable(summary.table.norge,digits = 3) %>%
  add_header_above(c("Model"=1,"Scaled LM" = 2, "LM" = 2, "Effect size" = 3),italic = T) %>%
  kable_styling(bootstrap_options = "bordered") %>%
  group_rows(group_label = "Model Evaluation", start_row = n+1,end_row=n+3)

knitr::kable(summary.table.sem.norge,digits = 4) %>%
  add_header_above(c("Model"=1,"Scaled SEM" = 2,"SEM" = 2, "Effect size" = 3),italic = T) %>%
  kable_styling(bootstrap_options = "bordered") %>%
  column_spec(column = 8, bold = T) %>% 
  group_rows(group_label = "Model Evaluation", start_row = n+1,end_row=n+2)
```

## Summary tables simple model Fennoscandia

```{r summary-table-simple-fen}

knitr::kable(summary.table.simple.lm,digits = 3) %>%
  add_header_above(c("Model"=1,"Scaled LM" = 2, "LM" = 2, "Effect size" = 3),italic = T) %>%
  kable_styling(bootstrap_options = "bordered") %>%
  group_rows(group_label = "Model Evaluation", start_row = n+1,end_row=n+3)

knitr::kable(summary.table.simple.sem,digits = 4) %>%
  add_header_above(c("Model"=1,"Scaled SEM" = 2,"SEM" = 2, "Effect size" = 3),italic = T) %>%
  kable_styling(bootstrap_options = "bordered") %>%
  column_spec(column = 8, bold = T) %>% 
  group_rows(group_label = "Model Evaluation", start_row = n+1,end_row=n+2)
```

```{r exit}
knitr::knit_exit()
```

# some extra code


```{r quick-ndvi-mode}
ndvi.model <- lm(ndvi~alt*temp, data = fennoscandia)
runoff.model <- lm(log.runoff~log.prec*slope, data = fennoscandia)
summary(ndvi.model)
summary(runoff.model)
```
* Precipitation
https://www.eea.europa.eu/data-and-maps/indicators/european-precipitation-2/assessment
5% is the minimum predicted increase in coastal regions in Norway, plutôt 20-30% à l'intéreur des terres

* Temperature: https://www.eea.europa.eu/data-and-maps/figures/trends-in-annual-temperature-across-1

RCP4.5 (intermediate scenario with a peak emission in 2040) = baseline scenario --> 3 to 4 degrees increase in Fennoscandia

RCP8.5 = worst case scenario: 5 to 6 degree increase in Fennoscandia

* Runoff
Increase in fennoscandia even during the dryest month(0 to 15)
https://www.eea.europa.eu/data-and-maps/indicators/river-flow-drought-3/assessment






```{r maps-fennoscandia}
uneven <- seq(1,50,2)
even <- seq(2,50,2)
map.list <- c()
for(i in 2:length(variables)){
  map <<- f_plotspatial(fennoscandia,fennoscandia[,variables[i]],plottitle = variables[i])+theme_void(base_size = 15)
  map.list[[even[i]]] <- map
}

```

```{r map-coef, fig.dim=c(10,30)}

for(i in 2:length(variables)){
  map <<- f_plotspatial(fennoscandia,gwr.fennoscandia$SDF@data[,variables[i]],plottitle = paste("coef",variables[i]))+theme_void(base_size = 15)
  map.list[[uneven[i]]] <- map
}

cowplot::plot_grid(plotlist = map.list,ncol=2)
```



