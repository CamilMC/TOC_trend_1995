---
title: "Remote sensing and toc concentration"
author: "Camille M. Crapart"
date: "29 9 2021"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    number_sections: true
#bibliography: C:\\Users\\raine\\Documents\\UiO\\Bibtex\\Finstad.bib
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, message = F, warning = F, error = F, fig.align = "center")
options(knitr.kable.NA="")
```
```{r library}
library(dplyr)
library(tibble)

library(DBI)
library(sf)
library(gimms)

library(ncdf4)
library(rgdal)

library(stringr)
library(ggplot2)
library(cowplot)
library(spdep)
library(spatialreg)

library(kableExtra)

source("f_plotspatial.R")
fennoscandia <- readRDS("fennoscandia.Rdata")
fennoscandia.spdf <- readRDS("fennoscandia.spdf.Rdata")

```

# Introduction

In boreal lakes, acid rains led to the acidification of the surface waters @Mens2004. Long-range transport of pollutants was first reported by Brøgger in Naturen in 1880. Then Dannevig in 1959 observed that acidification of water could lead to the death of fishes. In the 70s, Odén showed that the acidification of surface water in Norway originated from air pollution in the UK and in central Europe. Several studies emerged in order to follow-up the quality of surface water in Fennoscandia. A first regional study was conducted in 1986. It showed that most lakes had low ionic concentration, including nutrient concentration like nitrogen and phosphorus. It highlighted the gradient of precipitation and forested areas between the west of Norway and the east of Finland.  Between the period 76-85 and the period 95-2001, acid rains have been reduced by 50% @Mens2004. However, NOx deposition has decreased much less, due to the continued used of ammonia as a fertilizer. As a result, the pH of the lakes began to rise again. Reduced acidification affects the solubility of DOC @Finstad2016, therefore reducing the transport from terrestrial pools to lakes. This led to less dissolution of aluminium from bedrocks, and therefore less flocculation of TOC. Therefore, the TOC concentration in lakes began to rise as well.

The second sulfur protocol was signed in Oslo in 1994. It aimed at limiting sulfur and nitrogen concentrations under new critical loads. Therefore, new data collection was needed to establish an up-to-date reference dataset for the follow up of this protocol. This survey included Norway, Sweden, Finland, Denmark, as well as Scotland, Wales and Russian Kola and Karelia. A larger survey was conducted in including the Northern European Lake Survey in 1995 @Henriksen1998. It included a lot of variables, such as pH, conductivity, major ion concentrations, labile and non-labile Al. The study showed an increasing gradient from west to east. This reflects the presence of thin soil, poorly vegetated areas, and high runoff in western Norway, contrasting with the forests with thick soils and low runoff in the east. 
Based on this survey, Larsen et al. @Larsen2011 modelled the concentration of TOC with NDVI, bogs and runoff as independent variables. cite Heleen 2014 for runoff. Bogs? NDVI? They used a linear regression and obtained an R-squared of 0,82, showing that these 3 variables were good predictors of the TOC concentration in lakes. However they did not take into account the spatial autocorrelation of the variables. 
De Wit et al @DeWit2015 observed a significant increase of TOC between 1990 and 2013 in all of Fennoscandia. This support the fact that the browning is due to global or regional factors, and not local factors. “Strong relationship between the change in median annual OC and median annual precipitation”. This relationship depends on the dryness of the place, from high positive change in dry site to almost no change in wet sites.  increased OC mobilization in dry sites and dilution effect with additional rainfall in wettest sites. Since climatic models predict a 10% increase in precipitations, they suggest that OC would subsequently increase except in oceanic regions. 30-50% rise, due to increased “lateral flow through carbon-rich top soils layers”. Wetter climates may reduce the rate of OC decay because of less water retention

90% of TOC in boreal lakes is DOC source. It is the main source of food for heterotrophic bacteria. Increasing DOC concentration can turn the lake from a net autotrophic balance to a net heterotrophic balance. More DOC available means that less and less light will be available for autotrophic organisms. The light is indeed absorbed by the coloured DOC,  warming the upper layer of the lakes at the same time. 
We decided to extend the model over the full gradient western Norway – eastern Finland. We used the same explanatory parameters as Larsen et al. but we implemented a spatial error model to include the spatial autocorrelation effect. 

  
  
# Methods

## Data preparation
See data preparation

## Models
Description of models used

## Effect size

The estimate of the model is converted into effect size by the following formula.The estimate is called $$ \hat{\theta}$$.

$$
\log([TOC]_1) = \beta_{NDVI} \times NDVI_1 \\
\log([TOC]_2) = \beta_{NDVI} \times NDVI_2 \\
\log([TOC]_2) - \log([TOC]_1) = \beta_{NDVI} \times (NDVI_2 - NDVI_1) \\
\log([TOC]_2/[TOC_1]) = \beta_{NDVI} \times (\Delta_{NDVI}) \\
\frac{[TOC]_2}{[TOC_1]} = 10^{\beta_{NDVI} \times \Delta_{NDVI}}
$$

Therefore, the relative change of TOC can be expressed depending on a change of NDVI. If we choose to evaluate the relative change of TOC concentration based on a small increase of the value of NDVI (here 0.1), we obtain: 

$$
Effect \; size: \; h(\theta) = 10^{\beta_{NDVI} \times 0.1} \\
$$

The evaluation of the standard error is based on the delta method @MacKenzie2018:

$$
Var(h(\hat{\theta})) = (\frac{\delta h(\theta)}{\delta \hat{\theta}})^2 \times Var(\hat{\theta}) \\
Std(h(\hat{\theta})) = \sqrt{(\frac{\delta h(\theta)}{\delta \hat{\theta}})^2 \times Var(\hat{\theta})} = \frac{\delta h(\theta)}{\delta \hat{\theta}} \times Std(\hat{\theta}) \\
\frac{\delta h(\theta)}{\delta \hat{\theta}} = `ln(10) \times 10^{0.1 \hat{\theta}} \times 0.1 \\
Std(h(\hat{\theta})) = 0.1 \times 10^{\beta_{NDVI}} \times std.error_{NDVI}
$$

```{r early-exit}
knitr::knit_exit()
```
# Results

## Mapping of dependant and independant variables

```{r map-variable, fig.dim = c(10,13)}
m <- c("log.toc","ndvi","log.runoff","log.prec","slope","temp","bogs","arable","rdn","oxn")
u <- c("TOC concentration, log(mg/L)", "NDVI on scale 0 to 1", "Mean runoff, log(kg/m2/an)","Mean annual precipitation,\n log(mm)","Slope in degrees","Mean annual temperature,\n degree celsius","Proportion of bogs, %","Proportion of\narable land, %","Reduced nitrogen\ndeposition, ug/m2","Oxidized nitrogen\ndeposition, ug/m2")
list.map <- lapply(m,FUN = function(x)  f_plotspatial(data=fennoscandia,var=fennoscandia[[x]],plottitle = "")+annotate("text", x = 10, y = 69.5, label = paste(u[grep(x,m)],"\n(",x,")",sep="")))

cowplot::plot_grid(plotlist = list.map,ncol=2)
```

## Correlation between independant variables

```{r corrplot}

cor.mat <- cor(dplyr::select(fennoscandia,m))
corrplot::corrplot(cor.mat, method = "number",type = "lower")

```

## Spatial autocorrelation

```{r neighbour-matrix,  eval = F}
library(spdep)
k.neigh.set <- knearneigh(fennoscandia.spdf, k = 100)
k.neigh.nb.set <- knn2nb(k.neigh.set)
k.neigh.w <- nb2listw(k.neigh.nb.set)
saveRDS(k.neigh.w,"k.neigh.w.Rdata")
```

```{r spatial-autocorrelation, eval = T}
k.neigh.w <- readRDS("k.neigh.w.Rdata")
moran.list <- c() 

m <- c("log.toc","ndvi","log.runoff","log.prec","slope","temp","bogs","arable","rdn","oxn")

for (i in m){
  moran.list[[i]] <- moran.test(fennoscandia[,i],k.neigh.w, na.action = na.omit, alternative = "two.sided")
}

moran.df <- data.frame(m) %>% setNames("parameter")
moran.df$I <- NA
moran.df$p <- NA

for (i in 1:length(moran.list)){
  moran.df$I[i] <- moran.list[[i]]$estimate[1]
  moran.df$p[i] <- moran.list[[i]]$p.value
}

saveRDS(moran.df,"moran.df.Rdata")
```

```{r spatial-autocorrelation-plot, fig.cap = "Spatial autocorrelation of variables"}
moran.df <- readRDS("moran.df.Rdata")
moran.df <- moran.df %>% mutate(p_value = case_when(p < 0.001~"< 0.001",p < 0.05 ~ "< 0.05",p < 0.1 ~"< 0.1", p > 0.1 ~" > 0.1"))

moran.df$parameter <- factor(moran.df$parameter, levels = moran.df$parameter[order(moran.df$I)])

knitr::kable(moran.df, digits = 4, caption = "Moran'I of dependant and independant variable") %>% kable_styling(bootstrap_options = "bordered")
g.moran <- ggplot(filter(moran.df,!parameter %in% c("longitude","latitude", "id")))+
  geom_col(aes(x=I,y=parameter,fill=p_value))+
  scale_fill_viridis_d()+theme_light()+
  geom_vline(xintercept = 1/(dim(fennoscandia)[1]-1))

```

## OLS for Norway

```{r kmat, eval = F}
norge.spdf <- SpatialPointsDataFrame(norge[,c("longitude","latitude")],norge)

norge.kmat <- norge.spdf %>% knearneigh(k=50) %>% knn2nb %>% nb2listw
saveRDS(norge.kmat,"norge.kmat.Rdata")
```
```{r ols-norge, results = T}
norge.kmat <- readRDS("norge.kmat.Rdata")
norge <- fennoscandia %>% filter(nation == "Norway")

fm.s <- s.log.toc~s.ndvi+s.log.runoff+s.bogs
s.lm.norge <- lm(fm.s, data = norge, na.action = na.exclude)

fm <- log.toc~ndvi+log.runoff+bogs
lm.norge <- lm(fm, data = norge, na.action = na.exclude)

s.lm.r2 <- summary(s.lm.norge)$adj.r.squared
s.moran.I.res.lm <- lm.morantest(s.lm.norge, norge.kmat, alternative = "two.sided")

lm.r2 <- summary(lm.norge)$adj.r.squared
moran.I.res.lm <- lm.morantest(lm.norge, norge.kmat, alternative = "two.sided")

moran.limit.norge <- 1/(dim(norge)[1]-1)
  
s.lm.coef <- summary(s.lm.norge)$coefficients %>% as.data.frame()
s.lm.coef <- s.lm.coef %>% rownames_to_column(var = "Parameter")

lm.coef <- summary(lm.norge)$coefficients %>% as.data.frame()
lm.coef <- lm.coef %>% rownames_to_column(var = "Parameter")

lm.effectsize <- lm.coef[,1:3]

n <- length(lm.coef$Parameter)
m <- lm.coef$Parameter

for(i in 1:n){
  if(grepl("log",m[i])==T){
    lm.effectsize[i,2] <- 1.1^(lm.coef[i,2])
    lm.effectsize[i,3] <- 1.1^(lm.coef[i,2])*log(1.1)*lm.coef[i,3]
  }else if(m[i] %in% c("ndvi","bogs")){
    lm.effectsize[i,2] <- 10^(lm.coef[i,2]*0.1)
    lm.effectsize[i,3] <- 0.1*log(10)*10^(lm.coef[i,2]*0.1)*lm.coef[i,3]
  }
}

lm.effectsize$Percent <- 100*(lm.effectsize$Estimate-1)

summary.table.norge <- cbind(dplyr::select(lm.coef,Parameter),s.lm.coef[,2:3],lm.coef[,2:3],lm.effectsize[,2:4]) %>%
                rbind(c("AIC",AIC(s.lm.norge),"",AIC(lm.norge),"","","","")) %>%
                rbind(c("R2",s.lm.r2,"",lm.r2,"","","","")) %>%
                rbind(c("Moran'I res",s.moran.I.res.lm$estimate[[1]],"",moran.I.res.lm$estimate[[1]],"","","",""))
summary.table.norge[,-1] <- apply(summary.table.norge[,-1],2,as.numeric)

knitr::kable(summary.table.norge,digits = 3) %>%
  add_header_above(c("Model"=1,"Scaled LM" = 2, "LM" = 2, "Effect size" = 3),italic = T) %>%
  kable_styling(bootstrap_options = "bordered") %>%
  group_rows(group_label = "Model Evaluation", start_row = n+1,end_row=n+3)

```


## Ordinary least square regression for Fennoscandia

```{r ols-fennoscandia, results = T}
k.neigh.w <- readRDS("k.neigh.w.Rdata")

fm.s <- s.log.toc~s.ndvi+s.log.runoff+s.log.prec+s.slope+s.temp+s.bogs+s.arable+s.rdn+s.oxn
s.lm.fennoscandia <- lm(fm.s, data = fennoscandia, na.action = na.exclude)

fm <- log.toc~ndvi+log.runoff+log.prec+slope+temp+bogs+arable+rdn+oxn
lm.fennoscandia <- lm(fm, data = fennoscandia, na.action = na.exclude)

s.lm.r2 <- summary(s.lm.fennoscandia)$adj.r.squared
s.moran.I.res.lm <- lm.morantest(s.lm.fennoscandia, k.neigh.w, alternative = "two.sided")

lm.r2 <- summary(lm.fennoscandia)$adj.r.squared
moran.I.res.lm <- lm.morantest(lm.fennoscandia, k.neigh.w, alternative = "two.sided")

moran.limit.fennoscandia <- 1/(dim(fennoscandia)[1]-1)

lm.comparison <- data.frame(model = c("lm.scaled", "lm"),
                            r2 = c(s.lm.r2,lm.r2), 
                            AIC = c(AIC(s.lm.fennoscandia),AIC(lm.fennoscandia)),
                            moran.res = c(s.moran.I.res.lm$estimate[[1]], moran.I.res.lm$estimate[[1]]))

  
s.lm.coef <- summary(s.lm.fennoscandia)$coefficients %>% as.data.frame()
s.lm.coef <- s.lm.coef[-1,] %>% rownames_to_column(var = "Parameter")

lm.coef <- summary(lm.fennoscandia)$coefficients %>% as.data.frame()
lm.coef <- lm.coef[-1,] %>% rownames_to_column(var = "Parameter")

lm.effectsize <- lm.coef[,1:3]

n <- length(lm.coef$Parameter)
m <- lm.coef$Parameter

for(i in 1:n){
  if(grepl("log",m[i])==T){
    lm.effectsize[i,2] <- 1.1^(lm.coef[i,2])
    lm.effectsize[i,3] <- 1.1^(lm.coef[i,2])*log(1.1)*lm.coef[i,3]
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    lm.effectsize[i,2] <- 10^(lm.coef[i,2]*0.1)
    lm.effectsize[i,3] <- 0.1*log(10)*10^(lm.coef[i,2]*0.1)*lm.coef[i,3]
  }else if(m[i] %in% c("temp","rdn","oxn")){
    lm.effectsize[i,2] <- 10^(lm.coef[i,2]*1)
    lm.effectsize[i,3] <- 1*log(10)*10^(lm.coef[i,2]*1)*lm.coef[i,3]
  }
}

lm.effectsize$Percent <- 100*(lm.effectsize$Estimate-1)


```
```{r arm-sim-test-lm}
sm.fennoscandia <- arm::sim(lm.fennoscandia,n.sims = 100)

sm.coef <- sm.fennoscandia@coef[,-1]
sm.effectsize <- data.frame(parameter = colnames(sm.coef), effect.size = NA, std.error = NA)

n <- dim(sm.coef)[2]
m <- colnames(sm.coef)

for(i in 1:n){
  if(grepl("log",m[i])==T){
    sm.effectsize[i,2] <- mean(1.1^(sm.coef[,i]))
    sm.effectsize[i,3] <- sd(1.1^(sm.coef[,i])*log(1.1)*sm.coef[,i])
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    sm.effectsize[i,2] <- mean(10^(sm.coef[,i]*0.1))
    sm.effectsize[i,3] <- sd(0.1*log(10)*10^(sm.coef[,i]*0.1)*sm.coef[,i])
  }else if(m[i] %in% c("slope","temp","rdn","oxn")){
    sm.effectsize[i,2] <- mean(10^(sm.coef[,i]*1))
    sm.effectsize[i,3] <- sd(1*log(10)*10^(sm.coef[,i]*1)*sm.coef[,i])
  }
}

```
```{r lm-table-results}
summary.table.lm <- cbind(dplyr::select(lm.coef,Parameter),s.lm.coef[,2:3],lm.coef[,2:3],lm.effectsize[,2:4],sm.effectsize[,2:3]) %>%
                rbind(c("AIC",AIC(s.lm.fennoscandia),"",AIC(lm.fennoscandia),"","","","","","")) %>%
                rbind(c("R2",s.lm.r2,"",lm.r2,"","","","","","")) %>%
                rbind(c("Moran'I res",s.moran.I.res.lm$estimate[[1]],"",moran.I.res.lm$estimate[[1]],"","","","","",""))
summary.table.lm[,-1] <- apply(summary.table.lm[,-1],2,as.numeric)

knitr::kable(summary.table.lm,digits = 3) %>%
  add_header_above(c("Model"=1,"Scaled LM" = 2, "LM" = 2, "Effect size" = 3,"SIM" = 2),italic = T) %>%
  kable_styling(bootstrap_options = "bordered") %>%
  group_rows(group_label = "Model Evaluation", start_row = n+1,end_row=n+3)


```
## SEM

```{r sem, eval = F}
k.neigh.w <- readRDS("k.neigh.w.Rdata")
library(spatialreg)

lagrange <- lm.LMtests(lm.fennoscandia,k.neigh.w,test = c("LMerr","LMlag","RLMerr","RLMlag"))

fm.s <- s.log.toc~s.ndvi+s.log.runoff+s.log.prec+s.slope+s.temp+s.bogs+s.arable+s.rdn+s.oxn
s.sem.fennoscandia <- errorsarlm(fm.s,fennoscandia,k.neigh.w)
saveRDS(s.sem.fennoscandia,"s.sem.fennoscandia.Rdata")

fm <- log.toc~ndvi+log.runoff+log.prec+slope+temp+bogs+arable+rdn+oxn
sem.fennoscandia <- errorsarlm(fm,fennoscandia,k.neigh.w)
saveRDS(sem.fennoscandia,"sem.fennoscandia.Rdata")
```

```{r sem-results}
s.sem.fennoscandia <- readRDS("s.sem.fennoscandia.Rdata")
sem.fennoscandia <- readRDS("sem.fennoscandia.Rdata")
k.neigh.w <- readRDS("k.neigh.w.Rdata")


s.sem.coef <- s.sem.fennoscandia$coefficients %>% as.data.frame() %>% 
              setNames("Estimaste")
s.sem.coef <- s.sem.coef %>% rownames_to_column(var = "Parameter")
s.sem.coef$std.error <- s.sem.fennoscandia$rest.se

sem.coef <- sem.fennoscandia$coefficients %>% as.data.frame() %>% 
              setNames("Estimate")
sem.coef <- sem.coef %>% rownames_to_column(var = "Parameter")
sem.coef$std.error <- sem.fennoscandia$rest.se

sem.effectsize <- sem.coef[,1:3]

n <- length(sem.coef$Parameter)
m <- sem.coef$Parameter

for(i in 1:n){
  if(grepl("log",m[i])==T){
    sem.effectsize[i,2] <- 1.1^(sem.coef[i,2])
    sem.effectsize[i,3] <- 1.1^(sem.coef[i,2])*log(1.1)*sem.coef[i,3]
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    sem.effectsize[i,2] <- 10^(sem.coef[i,2]*0.1)
    sem.effectsize[i,3] <- 0.1*log(10)*10^(sem.coef[i,2]*0.1)*sem.coef[i,3]
  }else if(m[i] %in% c("slope","temp","rdn","oxn")){
    sem.effectsize[i,2] <- 10^(sem.coef[i,2]*1)
    sem.effectsize[i,3] <- 1*log(10)*10^(sem.coef[i,2]*1)*sem.coef[i,3]
  }
}

sem.effectsize$Percent <- 100*(sem.effectsize$Estimate-1)

s.sem.AIC <- 2*(n-1)-2*s.sem.fennoscandia$LL
sem.AIC <- 2*(n-1)-2*sem.fennoscandia$LL

s.moran.I.res.sem <- moran.test(s.sem.fennoscandia$residuals, k.neigh.w, alternative = "two.sided")

moran.I.res.sem <- moran.test(sem.fennoscandia$residuals, k.neigh.w, alternative = "two.sided")

summary.table.sem <- cbind(dplyr::select(sem.coef,Parameter),s.sem.coef[,2:3],sem.coef[,2:3],sem.effectsize[,2:4]) %>%
                rbind(c("AIC",s.sem.AIC,"",sem.AIC,"","","","")) %>%
                rbind(c("Moran'I res", s.moran.I.res.sem$estimate[[1]],"", moran.I.res.sem$estimate[[1]], "","","",""))
summary.table.sem[,-1] <- apply(summary.table.sem[,-1],2,as.numeric)

knitr::kable(summary.table.sem,digits = 4) %>%
  add_header_above(c("Model"=1,"Scaled SEM" = 2, "SEM" = 2, "Effect size" = 3),italic = T) %>%
  kable_styling(bootstrap_options = "bordered") %>%
  group_rows(group_label = "Model Evaluation", start_row = n+1,end_row=n+2)

```

## GWR model 

```{r GWR-fennoscandia, eval = F}
fm <- log.toc~ndvi+log.runoff+log.prec+slope+temp+bogs+arable+rdn+oxn

library(GWmodel)
bw.fennoscandia <- bw.gwr(fm, data = fennoscandia.spdf, kernel = "gaussian", adaptive = T)
gwr.fennoscandia <- gwr.basic(fm, data = fennoscandia.spdf, bw = 100, kernel = "gaussian", adaptive = T)

saveRDS(bw.fennoscandia, "bw.fennoscandia.Rdata")
saveRDS(gwr.fennoscandia, "gwr.fennoscandia.Rdata")
```


```{r gwr-results, fig.dim = c(10,13)}
bw.fennoscandia <- readRDS("bw.fennoscandia.Rdata")
gwr.fennoscandia <- readRDS("gwr.fennoscandia.Rdata")
k.neigh.w <- readRDS("k.neigh.w.Rdata")

gwr.coef <- gwr.fennoscandia$SDF@data

m <- c("ndvi","log.runoff","log.prec","slope","temp","bogs","arable","rdn","oxn")
n <- length(m)

gwr.effectsize <- gwr.coef[,2:(n+1)]

for(i in 1:n){
  if(grepl("log",m[i])==T){
    gwr.effectsize[i,2] <- 1.1^(gwr.coef[i,2])
#    gwr.effectsize[i,3] <- 1.1^(gwr.coef[i,2])*log(1.1)*gwr.coef[i,3]
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    gwr.effectsize[i,2] <- 10^(gwr.coef[i,2]*0.1)
#    gwr.effectsize[i,3] <- 0.1*log(10)*10^(gwr.coef[i,2]*0.1)*gwr.coef[i,3]
  }else if(m[i] %in% c("slope","temp","rdn","oxn")){
    gwr.effectsize[i,2] <- 10^(gwr.coef[i,2]*1)
#    gwr.effectsize[i,3] <- 1*log(10)*10^(gwr.coef[i,2]*1)*gwr.coef[i,3]
  }
}

gwr.effectsize.percent <- 100*(gwr.effectsize)-1

coef.plot <- lapply(m,FUN = function(x)  f_plotspatial(data=fennoscandia,var=gwr.effectsize.percent[[x]],plottitle = x))
cowplot::plot_grid(plotlist = coef.plot,ncol=2)

gwr.AIC <- gwr.fennoscandia$GW.diagnostic$AICc
gwr.r2 <- gwr.fennoscandia$GW.diagnostic$gwR2.adj
gwr.moran <- moran.test(gwr.coef$Stud_residual,k.neigh.w,alternative = "two.sided")

summary.table.gwr <- data.frame(AIC = gwr.AIC,R2 = gwr.r2,Moran.I =gwr.moran$estimate[[1]])
                                
knitr::kable(summary.table.gwr,digits = 3) %>%
  kable_styling(bootstrap_options = "bordered")
```

```{r exit}
knitr::knit_exit()
```


```{r quick-ndvi-mode}
ndvi.model <- lm(s.ndvi~s.temp+s.log.prec+s.tndep, data = fennoscandia)
summary(ndvi.model)
```
* Precipitation
https://www.eea.europa.eu/data-and-maps/indicators/european-precipitation-2/assessment
5% is the minimum predicted increase in coastal regions in Norway, plutôt 20-30% à l'intéreur des terres

* Temperature: https://www.eea.europa.eu/data-and-maps/figures/trends-in-annual-temperature-across-1

RCP4.5 (intermediate scenario with a peak emission in 2040) = baseline scenario --> 3 to 4 degrees increase in Fennoscandia

RCP8.5 = worst case scenario: 5 to 6 degree increase in Fennoscandia

* Runoff
Increase in fennoscandia even during the dryest month(0 to 15)
https://www.eea.europa.eu/data-and-maps/indicators/river-flow-drought-3/assessment





```{r arm-sim-test}
sm.fennoscandia <- arm::sim(lm.fennoscandia,n.sims = 100)

sm.coef <- sm.fennoscandia@coef[,-1]
sm.effectsize <- data.frame(parameter = colnames(sm.coef), effect.size = NA, std.error = NA)

n <- dim(sm.coef)[2]
m <- colnames(sm.coef)

for(i in 1:n){
  if(grepl("log",m[i])==T){
    sm.effectsize[i,2] <- mean(1.1^(sm.coef[,i]))
    sm.effectsize[i,3] <- sd(1.1^(sm.coef[,i])*log(1.1)*sm.coef[,i])
  }else if(m[i] %in% c("ndvi","bogs","arable")){
    sm.effectsize[i,2] <- mean(10^(sm.coef[,i]*0.1))
    sm.effectsize[i,3] <- sd(0.1*log(10)*10^(sm.coef[,i]*0.1)*sm.coef[,i])
  }else if(m[i] %in% c("temp","rdn","oxn")){
    sm.effectsize[i,2] <- mean(10^(sm.coef[,i]*1))
    sm.effectsize[i,3] <- sd(1*log(10)*10^(sm.coef[,i]*1)*sm.coef[,i])
  }
}

```
```{r all-coef-table}
all.coef <- cbind(lm.coef[-1,1:3], lm.coef.rc[-1,1:3],lm.coef.backtransformed)
knitr::kable(all.coef, digits = 3)
```




```{r maps-fennoscandia}
uneven <- seq(1,50,2)
even <- seq(2,50,2)
map.list <- c()
for(i in 2:length(variables)){
  map <<- f_plotspatial(fennoscandia,fennoscandia[,variables[i]],plottitle = variables[i])+theme_void(base_size = 15)
  map.list[[even[i]]] <- map
}

```

```{r map-coef, fig.dim=c(10,30)}

for(i in 2:length(variables)){
  map <<- f_plotspatial(fennoscandia,gwr.fennoscandia$SDF@data[,variables[i]],plottitle = paste("coef",variables[i]))+theme_void(base_size = 15)
  map.list[[uneven[i]]] <- map
}

cowplot::plot_grid(plotlist = map.list,ncol=2)
```

# Summary

```{r summary-performances, eval= T}
models <- c("OLS","SEM","GWR")
AIC.models <- c(AIC(lm.fennoscandia),2*length(variables[-1])-2*sem.fennoscandia$LL,gwr.fennoscandia$GW.diagnostic$AICc)
moran.res.models <- c(moran.I.res.lm$estimate[1],moran.I.res.sem$estimate[1],moran.I.res.gwr$estimate[1])

summary.table <- data.frame(models = models, AIC = AIC.models, moran.I = moran.res.models)
knitr::kable(summary.table)  
```


