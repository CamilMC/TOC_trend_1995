---
title: "TOC and water chemistry in Fennoscandian lakes"
author: "Camille M. Crapart"
date: "12 5 2021"
output:
  bookdown::html_document2: default
  word_document: default
#runtime: shiny
bibliography: C:\\Users\\raine\\Documents\\UiO\\Bibtex\\Finstad.bib
link-citations: yes

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F, error = F, fig.align = "center")
```

```{r libraries, message = F}
library(readxl)
library(GWmodel)
library(ggplot2)
library(dplyr)
library(reshape2)
library(RColorBrewer)
library(shiny)
library(rstatix)
library(spdep)
library(tidyr)
library(gridExtra)
library(grid)

source("f_plotspatial.R")
```
# Introduction

# Method
## Dataset

The data-set comes from four different data sources. a) The Fennoscandian lake catchment database (Blumentrath et al., unpublished), for which b) Corine land-cover (http://www.eea.europa.eu/publications/COR0-landcover) and c) CORDEX (http://www.cordex.org/) near-surface temperature and runoff have been extracted as area of catchment covered and mean? yearly? (check with Koji which year and which statistics that actually was exctracted), respectively. Finally, this have been matched with water chemistry data from the 1995 survey described by Hendriksen et al. (1997). Human population density is givan as number of persons pr km2 and comes from GEOSTAT_Grid_POP_2006_1K, European Commission. Downloaded from http://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/population-distribution-demography/geostat

Data are, following extraction of catchment characteristics (not described here) stored on the ecco_biwa database in several tables. Using the dplyr package (Wickham and Francois 2016, v. 0.5.0, https://CRAN.R-project.org/package=dplyr) to connect to database and merge data. This is decribed in the R-script R/dataIO.R. Serval on the fly data wrangling and transformations done while importing. a) Corine landcover classes are merged as described in script below. b) NDVI is defined as summer NDVI (June to August) with one year lag (following Finstad et al. 2016, doi:10.1038/srep31944). c) Temperature is given in kelvin for raw data, transformed to celsius.

**Notes:** The variable “ebint” referes to internal waterbody identifier (waterbodyID) used internally by the database. This identifier is not meaningfull outside this dataset. Also, the 1995 Northern European lake survey data did not come with explicit linkage to specific water bodies. Linkages to water bodies (and hence to catchments) where provided by spatially matching given coordinates to lake polygons. There are a number of lakes where the coordinates don’t mach exactly, but for most of these lakes the was no close by lake to mix up with. However, for 434 out of 4677 lakes in the data set, the next closest lake polygon was > 1/2 as far from the given coordinate as the closest. These are marked as waterBodyID_uncertain==TRUE

```{r load-data, fig.dim = c(2,2), fig.show='hold', results = F}
dim_waterchem <- read_xlsx("waterchem_1995.xlsx") %>% dim()
waterchem_1995 <- read_xlsx("waterchem_1995.xlsx",col_types = c("skip","skip","skip","text",rep("numeric",dim_waterchem[2]-5),"logical"),na = "NA")
```

## Data-cleaning
Visual inspection of the data show a number of obvious erronous data-points in both the 1995 water chemistry dataset and the climate data (runoff). In addition, records for which identity could not be established due to lack of precice georefference in the 1995 water chemistry dataset is removed (see above, step A). A few waterchemistry records showed duplicates within waterbodies. This is likely as a result of different classification of what constitutes a waterbody between the lake polygons and the 1995 study.

Hence, data records holding the following criteria where removed from the dataset prior to further analyses:

* Obvious errors in run-off data where runoff > 1 kg -2 s-1,(331 records).
* Negative TOC values, (81 records).
* Lakes for which identity (watebodyID), and hence the match between datasources was doubtfull and waterBodyID_uncertain==TRUE, (434 records).
* One record with obvious erroneous NDVI measures (< 0).
lakes with unrealistic high TOTP (> 200 ug l-1) or negative TOTP values.
* TOC, catchment and lake area where log transformed, and numeric fields where standardized by detracting mean and dividing on standard deviation using the scale function of the base library.

```{r data-cleaning}

waterchem_1995 <- waterchem_1995[waterchem_1995$runoff < 1e-04, ]
waterchem_1995 <- waterchem_1995[waterchem_1995$toc >= 0, ]
waterchem_1995 <- waterchem_1995[waterchem_1995$waterBodyID_uncertain == FALSE, 
    ]
waterchem_1995 <- waterchem_1995[waterchem_1995$ndvi_summer_lag1yr > 0, ]
waterchem_1995 <- waterchem_1995[is.na(waterchem_1995$Latitude) == FALSE, ]
waterchem_1995 <- waterchem_1995[is.na(waterchem_1995$Longitude) == FALSE, ]
waterchem_1995 <- waterchem_1995[waterchem_1995$so4 < 1000, ]
waterchem_1995 <- waterchem_1995[waterchem_1995$totp < 200 & waterchem_1995$totp > 
    0, ]
waterchem_1995 <- waterchem_1995[duplicated(waterchem_1995$Latitude) == FALSE, 
    ]
waterchem_1995$waterBodyID_uncertain <- NULL

```

# Results
## Distribution of variables
```{r shiny-distribution, eval = F}
num_var <- sapply(waterchem_1995,is.numeric) %>% as.vector()
#lapply(names(waterchem_1995)[which(num_var == T)], function(j) ggplot(waterchem_1995[,-1])+geom_histogram(aes_string(j))+theme_light())

# https://shiny.rstudio.com/tutorial/
ui_1 <- fluidPage(
  selectInput(inputId = "covariate", label = "Choose a covariate",choices = names(waterchem_1995)[which(num_var == T)]),
  plotOutput(outputId = "hist")
)

binwidth_hist <- function(x){
  if(IQR(x)==0){ 
    bw <- length(x)
  }else{
      bw <- 2*IQR(x)/(length(x)^(1/3))
    }
return(bw)
  }

server_1 <- function(input,output){
  output$hist <- renderPlot({
    ggplot(waterchem_1995[,-1])+geom_histogram(aes_string(input$covariate),binwidth = function(x) binwidth_hist(x))+theme_light()
  })
}
shinyApp(ui = ui_1, server = server_1, options = list(height = 500))

```

```{r histograms-variables, fig.cap = "histograms", fig.dim = c(10,8)}
binwidth_hist <- function(x){
  if(IQR(x, na.rm = T)==0){ 
    bw <- length(x)
  }else{
      bw <- 2*IQR(x, na.rm = T)/(length(x)^(1/3))
    }
return(bw)
}

waterchem_long <- pivot_longer(waterchem_1995,!lake_name, names_to = "expvar", values_to = "value") %>% group_by(expvar) %>% mutate(bw = binwidth_hist(value))


#ggplot(waterchem_long,aes(value))+facet_wrap(~expvar,scales = "free")+
  # geom_histogram(binwidth = function(x) binwidth_hist(x))+ theme_bw(base_size = 10) +
  # theme(strip.background = element_rect(fill = "white"), strip.text.x = element_text(size = 5, margin = margin()), strip.text.y = element_text(size = 3, margin = margin()))+guides(x = guide_axis(angle = 90)) 
  

# faire un plus petit strip 

h_list <- c()

for (i in names(waterchem_1995)[-1]){
  hi <- ggplot(waterchem_1995, aes_string(i))+geom_histogram(na.rm = TRUE, binwidth = function(x) binwidth_hist(x))+ylab("")
  h_list[[i]] <- hi
}

h_grobs <- lapply(h_list,ggplotGrob)

grobz.plot <- arrangeGrob(grobs = h_grobs,ncol = 3)
grid.draw(grobz.plot)


```

Many variables were skewed to the right: 

* so4
* non_marine_so4
* s-dep (with a lot of zeros)
* totp
* totn
* toc
* ca
* catchment_area_km2
* woodland (also many zeros) / woodland mixed / woodland leaved / woodland coniferous / agriculture / schrub / bare / bogs / water / glacier / population / runoff / lake area
* slope

Variables skewed to the left: 

* ndvi

To remedy to the non-normality of data distribution, all the right-skewed variables were log-transformed. In addition, they were scaled and centered to ease the comparison between the explanatory variables. 

```{r transforming-data}
# transforming data
waterchem_1995_log <- as.data.frame(waterchem_1995$lake_name)
waterchem_1995_log$log_toc <- log10(waterchem_1995$toc)
waterchem_1995_log$log_totp <- log10(waterchem_1995$totp)
waterchem_1995_log$log_totn <- log10(waterchem_1995$totn)
waterchem_1995_log$log_so4 <- log10(waterchem_1995$so4)
waterchem_1995_log$log_ca <- log10(waterchem_1995$ca)
waterchem_1995_log$log_lake_area <- log10(waterchem_1995$lake_area_km2)
waterchem_1995_log$log_catchm_area <- log10(waterchem_1995$catchment_area_km2)
waterchem_1995_log$log_woodland <- log10(waterchem_1995$woodland + 0.001)
waterchem_1995_log$log_bogs <- log10(waterchem_1995$bogs + 0.001)
waterchem_1995_log$log_runoff <- log10(waterchem_1995$runoff + 0.001)
waterchem_1995_log$log_population <- log10(waterchem_1995$population + 0.001)
waterchem_1995_log$ndvi <- waterchem_1995$ndvi_summer_lag1yr



# select numeric input variables, standarize, and merge back with main dataframe
waterchem_1995_std <- waterchem_1995_log[,-1] %>% scale(center = T, scale = T)
colnames(waterchem_1995_std) <- paste("std", colnames(waterchem_1995_std), sep = "_")  # rename columns of std. data
waterchem_1995_std <- as.data.frame(waterchem_1995_std)
waterchem_1995_full <- cbind(waterchem_1995, waterchem_1995_log[,-1], waterchem_1995_std)  # merge back with original data

waterchem_1995_spdf <- SpatialPointsDataFrame(waterchem_1995_full[c("Longitude","Latitude")],waterchem_1995_full)

```

## Correlations between dependent and independent variables

```{r correlations, fig.dim = c(10,10), fig.cap = 'Correlation matrix between dependent and independent variables'}
waterchem_cor <- cor_mat(waterchem_1995_log[,-1])
waterchem_pmat <- cor_pmat(waterchem_1995_log[,-1])
cor_plot(waterchem_cor,  p.mat = waterchem_pmat, method = "color",label = T,type = "lower", insignificant = "blank",font.label = list(size = 1))

```

Resp var: TOC

Covariates:

* log_totp (log_TN)
* log_SO4 (log_Ca, log TN)
* log_catchm_area (log_lake_area + log_population)
* log_woodland(ndvi)
* log_bogs
* log_runoff (logCa)

ndvi: à part

Distribution of log_woodlang has 2 peaks. So with the high correlation between woodland and ndvi, I pick NDVI which is normally distributed. 


```{r scatterplot_selection, fig.dim = c(20,20), eval = F}

car::scatterplotMatrix(select(waterchem_1995_full,c("log_toc","log_totp","log_so4","log_catchm_area","log_bogs","log_runoff","ndvi")),regLine = list(col = "red"),col="black")
```


## Spatial autocorrelation of data
@Koh2020
paper sur Moran's I?
The Moran'I of each dependent and independant parameter was calculated using the package "spdep" @Bivan2009. It is a measure of the clusterisation of the studied variable, which can take a value between -1 and 1. Randomly distributed values have a Moran's I close to 0. Moran's I and their respective p-value are represented in \@ref(fig:spatial-autocorrelation). The test is realized on log-transformed values to respect the assumption of normality. All p-values were significant (< 0.001). NDVI, log(TN), log(TOC), log(SO4) and log(runoff) have a Moran's I superior to 0.5, indicating a high level of spatial autocorrelation. log(TP), log(Ca) and log(woodland) were also highly autocorrelated (with Moran's I between 0.4 and 0.5). Lake and catchment area, as well as log(bogs), are however randomly distributed. 
Since our dependent variable log(TOC) is spatially autocorrelated, we need to apply a statistical method taking this correlation into account. 

```{r spatial-autocorrelation, fig.cap = "Moran's I coefficients for the independent variables"}

k_neigh <- knearneigh(waterchem_1995_spdf,k = 100)
k_neigh_nb <- knn2nb(k_neigh)
k_neigh_w <- nb2listw(k_neigh_nb)
moran_I_toc <- moran.test(waterchem_1995$toc,k_neigh_w)

moran_list <- c() 
for (i in names(waterchem_1995_log)[-1]){
  moran_list[[i]] <- moran.test(waterchem_1995_log[,i],k_neigh_w)
}

moran_df <- data.frame(names(waterchem_1995_log)[-1]) %>% setNames("parameter")
moran_df$I <- NA
moran_df$p <- NA

for (i in 1:length(moran_list)){
  moran_df$I[i] <- moran_list[[i]]$estimate[1]
  moran_df$p[i] <- moran_list[[i]]$p.value
}

moran_df <- moran_df %>% mutate(p_value = case_when(p < 0.001~"< 0.001",p < 0.05 ~ "< 0.05",p < 0.1 ~"< 0.1"))
ggplot(moran_df)+geom_col(aes(x=I,y=parameter,fill=p_value))+scale_fill_viridis_d()+theme_light()+geom_vline(xintercept = 0.5)

```

## Ordinary least square regression 
```{r OLS, fig.cap = "Regression coefficients for OLS"}
ols_std <- lm(std_log_toc~std_log_totp+std_log_so4+std_log_catchm_area+std_log_bogs+std_log_runoff+std_ndvi,data = waterchem_1995_std)
summary(ols_std)
plot(ols_std)

ols_summary <- data.frame(names(ols_std$coefficients), ols_std$coefficients,summary(ols_std)$coefficients[,4]) %>% setNames(c("parameter","coefficient","p"))
ols_summary <- ols_summary %>% mutate(p_value = case_when(p < 0.001~"< 0.001",p < 0.05 ~ "< 0.05",p < 0.1 ~"< 0.1"))

ols_res <- ols_std$residuals %>% as.data.frame() %>% setNames("residuals")
ols_res$long <- waterchem_1995$Longitude
ols_res$lat <- waterchem_1995$Latitude

moran_res <- moran.test(ols_res$residuals,k_neigh_w)

ggplot(ols_summary[-1,])+geom_col(aes(x=coefficient, y = parameter,fill=p_value))+scale_fill_viridis_d(end = 0.8)+theme_light()
```

The Moran's I of the residuals is `r moran_res$estimates[1]` and its p-value is `r moran_res$p.value`. (see \@ref(fig:map-residuals)). This shows that the residuals are not spatially correlated. The ordinary least square regression gives overall satisfactory results. 

```{r map-residuals, fig.cap = "Map of residuals"}
ggplot(ols_res)+geom_point(aes(x=long,y=lat,col=residuals))+theme_void()+scale_colour_gradient2(low="#4575B4",mid="#FFFFBF",high = "#D73027",midpoint = 0)+borders(database = "world", regions = c("Norway","Sweden","Finland"),xlim=c(0,35),ylim=c(55,73))

```


## Geographically weigthed analysis
Info @Meik2017

Given the clustering of the variables, a geographically weighted regression is likely to give better results than an ordinary one. The computations were realised with the "GWmodel" package on R @Harris2021.


### Geographically weighted correlations
```{r GWSS}

#bw_gwss <- bw.gwss.average(waterchem_1995_spdf,vars=c("std_log_toc","std_log_totp","std_log_so4","std_log_catchm_area","std_log_woodland","std_log_bogs","std_log_runoff","std_ndvi"),kernel = "gaussian", adaptive = T)

#gw_ss2 <- gwss(waterchem_1995_spdf,vars = c("toc","totp","so4","catchment_area_km2","woodland","bogs","runoff","ndvi_summer_lag1yr"),kernel = "gaussian",adaptive = T, bw = bw_gwss)

#save(gw_ss,file = "gw_ss.RData",envir = .GlobalEnv)
#save(bw_gwss, file = "bw_gwss.Rdata, envir = .GlobalEnv")

library(miceadds)
gw_ss_load <- "gw_ss"
gw_ss_load <- load.Rdata("gw_ss.RData", gw_ss_load)

waterchem_gwss <- gw_ss_load$SDF@data
waterchem_gwss_toc <- waterchem_gwss[,grep("toc",names(waterchem_gwss))]
```

```{r shiny-gwss, eval = F}

ui <- fluidPage(
  selectInput(inputId = "correlation_toc", label = "Variable to display",choices = names(waterchem_gwss_toc)),
  plotOutput(outputId = "map_toc")
)

server <- function(input,output){
  output$map_toc <- renderPlot({
    f_plotspatial(data = waterchem_1995, var = waterchem_gwss_toc[,input$correlation_toc], plottitle = input$correlation,col = "RdYlBu")
  })
}
shinyApp(ui = ui, server = server, options = list(height = 500))

```

The geographically weighted Pearson correlation coefficients for TOC are represented in figure \@ref(fig:map-gwss)

```{r map-gwss, fig.cap = "Maps of pearson correlation coefficients", fig.dim = c(10,10)}

corr_toc <- waterchem_gwss_toc[,grep("Corr_", names(waterchem_gwss_toc))]
corr_toc$Longitude <- waterchem_1995$Longitude
corr_toc$Latitude <- waterchem_1995$Latitude

c_list <- c()

for (i in names(corr_toc)[-which(names(corr_toc) %in% c("Latitude","Longitude"))]){
ci <- ggplot(corr_toc, aes(x=Longitude,y=Latitude)) +   geom_point(aes_string(col = i))+
    scale_colour_gradient2(low="#4575B4",mid="#FFFFBF",high = "#D73027",midpoint = 0)+
    borders(database = "world", regions = c("Norway","Sweden","Finland"), 
    fill = NA, colour = "grey50",xlim=c(0,35),ylim=c(55,73)) + 
    xlab("") + ylab("") +
    theme_void()
c_list[[i]] <- ci
}

c_grobs <- lapply(c_list,ggplotGrob)

grobc.plot <- arrangeGrob(grobs = c_grobs,ncol = 3)
grid.draw(grobc.plot)
```

### GWR
A model with the standardized log(TOC) and the standardised explanatory variables was run using the GWR package  

```{r GWR, results = 'hide'}

#gw.pcplot(data=waterchem_1995_spdf,vars= names(waterchem_1995),focus = 1, bw = 100, adaptive = T)
waterchem_std_spdf <- SpatialPointsDataFrame(waterchem_1995_full[c("Longitude","Latitude")],waterchem_1995_std)
# selects bandwidth

bw_std <- bw.gwr(std_log_toc~std_log_totp + std_log_so4+std_log_catchm_area+std_log_bogs+std_log_runoff+std_ndvi,data = waterchem_std_spdf,adaptive = T)

# computes bwr
gwr_std <- gwr.basic(std_log_toc~std_log_totp + std_log_so4+std_log_catchm_area+std_log_bogs+std_log_runoff+std_ndvi,data = waterchem_std_spdf, regression.points = waterchem_std_spdf, bw = bw_std, adaptive = T)

#gwr_cv <- gwr.model.selection(DeVar = "std_log_toc", InDeVars = c("std_log_totp","std_log_so4","std_log_catchm_area","std_log_bogs","std_log_runoff","std_ndvi"), data = waterchem_std_spdf, bw = bw_std, adaptive = T, kernel="gaussian",approach="aic")

waterchem_std_gwr <- gwr_std$SDF@data
model_gwr <- data.frame(gwr_std$lm$residuals, gwr_std$lm$fitted.values, gwr_std$lm$effects) %>% setNames(c("residuals","fitted.values","effects"))


```

```{r shiny-gwr, eval = F}
ui_2 <- fluidPage(
  selectInput(inputId = "coeff", label = "Regression coefficients",choices = names(waterchem_std_gwr)),
  plotOutput(outputId = "map_coeff")
)

server_2 <- function(input,output){
  output$map_coeff <- renderPlot({
    f_plotspatial(data = waterchem_1995, var = waterchem_std_gwr[,input$coeff], plottitle = input$coeff,col = "RdYlBu")
  })
}
shinyApp(ui = ui_2, server = server_2, options = list(height = 500))

```
```{r shiny-model-gwr, eval = F}
ui_3 <- fluidPage(
  selectInput(inputId = "model", label = "Select model parameter", choices = names(model_gwr)),
  plotOutput(outputId = "map_model")
  )

server_3 <- function(input,output){
  output$map_model <- renderPlot({
    f_plotspatial(data = waterchem_1995, var = model_gwr[,input$model], plottitle = input$model, col = "RdYlBu")
  })
}

shinyApp(ui = ui_3, server = server_3, options = list(height = 500))
```

```{r explore-gwr}
ggplot(model_gwr)+geom_point(aes(x=fitted.values,y=residuals))+theme_light()
boxplot(waterchem_1995_std$std_log_toc)
```
```{r map-residuals-GWR}
f_plotspatial(waterchem_1995, var = model_gwr$residuals, plottitle = "")
moran_gwr_res <- moran.test(model_gwr$residuals,k_neigh_w)
```
The Moran's I of the residuals is `r moran_gwr_res$estimate[1]` and its p-value is `r moran_gwr_res$p.value`. This shows that the residuals are not autocorrelated. 

```{r shiny-download, eval = F}
ui <- fluidPage(
    downloadButton("report", "Generate report"))

server <- function(input, output) {
    output$report <- downloadHandler(
      # For PDF output, change this to "report.pdf"
      file = "Finstad_analysis.html",
      content = function(filename) {
        rmarkdown::render("Finstad_analysis.Rmd",
          envir = new.env(parent = globalenv())
        )
      })
}


        
shinyApp(ui,server)
        
```